var documenterSearchIndex = {"docs":
[{"location":"high-level/nameddims/#Named-Dimensions-Workflow","page":"Named Dimensions","title":"Named Dimensions Workflow","text":"Named dimensions provide a type-safe, self-documenting way to work with MRI data. This guide explains how to use NamedDims.jl with MriReconstructionToolbox for clearer, less error-prone code.","category":"section"},{"location":"high-level/nameddims/#Why-Named-Dimensions?","page":"Named Dimensions","title":"Why Named Dimensions?","text":"","category":"section"},{"location":"high-level/nameddims/#The-Problem-with-Raw-Arrays","page":"Named Dimensions","title":"The Problem with Raw Arrays","text":"Consider this common mistake:\n\n# Raw arrays - easy to mix up dimensions\nksp = rand(ComplexF32, 256, 256, 8, 20)  # What do these dimensions mean?\n                                         # Is it (kx, ky, coil, time)?\n                                         # Or (kx, ky, time, coil)?\n                                         # Or something else?\n\n# Easy to make mistakes\nresult = sum(ksp, dims=3)  # Did we mean to average over coils?\n                            # Or time? Hard to tell!\nnothing # hide","category":"section"},{"location":"high-level/nameddims/#The-Solution:-Named-Dimensions","page":"Named Dimensions","title":"The Solution: Named Dimensions","text":"using NamedDims\n\n# Named dimensions - crystal clear\nksp = NamedDimsArray{(:kx, :ky, :coil, :time)}(\n    rand(ComplexF32, 256, 256, 8, 20)\n)\n\n# Now it's obvious what we're doing\nresult = sum(ksp, dims=:coil)  # Clearly averaging over coils\nslice = ksp[kx=128, ky=1:256, coil=1, time=:]  # Self-documenting indexing\nnothing # hide\n\nBenefits:\n\n‚úÖ Prevents dimension mix-ups - Compiler catches dimension errors\n‚úÖ Self-documenting code - Clear what each dimension represents\n‚úÖ Safer refactoring - Reorder dimensions without breaking code\n‚úÖ Better IDE support - Autocomplete shows dimension names","category":"section"},{"location":"high-level/nameddims/#Getting-Started","page":"Named Dimensions","title":"Getting Started","text":"","category":"section"},{"location":"high-level/nameddims/#Installation","page":"Named Dimensions","title":"Installation","text":"NamedDims.jl is re-exported by MriReconstructionToolbox:\n\nusing MriReconstructionToolbox\n# NamedDims is now available","category":"section"},{"location":"high-level/nameddims/#Creating-Named-Arrays","page":"Named Dimensions","title":"Creating Named Arrays","text":"# Start with regular array\nksp_data = rand(ComplexF32, 256, 256, 8)\n\n# Add names\nksp = NamedDimsArray{(:kx, :ky, :coil)}(ksp_data)\n\n# Or in one line\nksp = NamedDimsArray{(:kx, :ky, :coil)}(\n    rand(ComplexF32, 256, 256, 8)\n)\nnothing # hide","category":"section"},{"location":"high-level/nameddims/#Dimension-Naming-Conventions","page":"Named Dimensions","title":"Dimension Naming Conventions","text":"","category":"section"},{"location":"high-level/nameddims/#K-Space-Dimensions","page":"Named Dimensions","title":"K-Space Dimensions","text":"Standard names for k-space data: :kx, :ky, :kz or :z, :coil\n\n# 2D single-coil\nksp = NamedDimsArray{(:kx, :ky)}(...)\n\n# 2D multi-coil\nksp = NamedDimsArray{(:kx, :ky, :coil)}(...)\n\n# 3D single-coil\nksp = NamedDimsArray{(:kx, :ky, :kz)}(...)\n\n# 3D multi-coil\nksp = NamedDimsArray{(:kx, :ky, :kz, :coil)}(...)\n\nnote: Note\nThe presence of the :kz dimension indicates 3D data. If :kz is absent, the data is treated as 2D. Multi-slice data should include :z as the first batch dimension, not :kz or :slice.","category":"section"},{"location":"high-level/nameddims/#Image-Dimensions","page":"Named Dimensions","title":"Image Dimensions","text":"Standard names for image space: :x, :y, :z, :coil\n\n# 2D image\nimg = NamedDimsArray{(:x, :y)}(...)\n\n# 2D image with coils (before combination)\nimg = NamedDimsArray{(:x, :y, :coil)}(...)\n\n# 3D image\nimg = NamedDimsArray{(:x, :y, :z)}(...)","category":"section"},{"location":"high-level/nameddims/#Batch-Dimensions","page":"Named Dimensions","title":"Batch Dimensions","text":"Additional dimensions for multi-dimensional data can be freely named:\n\n# Dynamic 2D (time series)\nksp = NamedDimsArray{(:kx, :ky, :coil, :time)}(...)\n\n# Multi-slice 2D\nksp = NamedDimsArray{(:kx, :ky, :coil, :z)}(...)\n\n# Multi-contrast\nksp = NamedDimsArray{(:kx, :ky, :coil, :contrast)}(...)\n\n# Multiple batch dimensions\nksp = NamedDimsArray{(:kx, :ky, :coil, :z, :contrast)}(...)\n\n# 3D dynamic\nksp = NamedDimsArray{(:kx, :ky, :kz, :coil, :time)}(...)","category":"section"},{"location":"high-level/nameddims/#Working-with-Named-Arrays","page":"Named Dimensions","title":"Working with Named Arrays","text":"","category":"section"},{"location":"high-level/nameddims/#Indexing","page":"Named Dimensions","title":"Indexing","text":"ksp = NamedDimsArray{(:kx, :ky, :coil, :time)}(\n    rand(ComplexF32, 256, 256, 8, 30)\n)\n\n# Named indexing - clear and safe\nfirst_coil = ksp[coil=1]  # All data from first coil\ncenter_kspace = ksp[kx=128, ky=128, coil=:, time=:]\ncenter_kspace = ksp[kx=128, ky=128]  # same as above\ntime_series = ksp[kx=128, ky=128, coil=1, time=:]\n\n# Mix names and regular indices\nmiddle_time = ksp[:, :, :, 15]  # Still works\n# Or better:\nmiddle_time = ksp[time=15]  # Clearer!\n\n# Ranges\nsubregion = ksp[kx=100:150, ky=100:150, coil=:, time=1:10]\nnothing # hide","category":"section"},{"location":"high-level/nameddims/#Reductions","page":"Named Dimensions","title":"Reductions","text":"# Named dimensions make reductions clear\nmean_over_time = mean(ksp, dims=:time)\nsum_over_coils = sum(ksp, dims=:coil)\nstd_spatial = std(ksp, dims=(:kx, :ky))\n\n# Result preserves other dimension names\n# If ksp is (:kx, :ky, :coil, :time)\n# mean(ksp, dims=:time) is (:kx, :ky, :coil, :time) with size(..., ..., ..., 1)","category":"section"},{"location":"high-level/nameddims/#Dimension-Queries","page":"Named Dimensions","title":"Dimension Queries","text":"# Get dimension names\ndimnames(ksp)  # Returns (:kx, :ky, :coil, :time)\n\n# Check if dimension exists\n:time in dimnames(ksp)  # true\n:z in dimnames(ksp)     # false","category":"section"},{"location":"high-level/nameddims/#Using-with-MriReconstructionToolbox","page":"Named Dimensions","title":"Using with MriReconstructionToolbox","text":"","category":"section"},{"location":"high-level/nameddims/#Automatic-Operator-Creation","page":"Named Dimensions","title":"Automatic Operator Creation","text":"The package automatically handles named dimensions:\n\nksp = NamedDimsArray{(:kx, :ky, :coil)}(\n    rand(ComplexF32, 256, 256, 8)\n);\n\nsmaps = NamedDimsArray{(:x, :y, :coil)}(\n    coil_sensitivities(256, 256, 8)\n);\n\ndata = AcquisitionInfo(ksp; sensitivity_maps=smaps)\n\nE = get_encoding_operator(ksp; sensitivity_maps=smaps)\nE = get_encoding_operator(data)  # Same result\n\nimg = E' * ksp;\ndimnames(img)","category":"section"},{"location":"high-level/nameddims/#Reconstruction-with-Named-Dimensions","page":"Named Dimensions","title":"Reconstruction with Named Dimensions","text":"# High-level reconstruct function\nimg = reconstruct(AcquisitionInfo(ksp; sensitivity_maps=smaps))\n\n# Result has named dimensions\ndimnames(img)  # (:x, :y)\n\n# Can index result by name\ncenter_pixel = img[x=128, y=128]","category":"section"},{"location":"high-level/nameddims/#Dimension-Inference","page":"Named Dimensions","title":"Dimension Inference","text":"The package infers 2D vs 3D from dimension names:\n\n# 2D - no :kz dimension\nksp_2d = NamedDimsArray{(:kx, :ky, :coil)}(...)\nE_2d = get_encoding_operator(ksp_2d)  # Creates 2D operator\n\n# 3D - has :kz dimension\nksp_3d = NamedDimsArray{(:kx, :ky, :kz, :coil)}(...)\nE_3d = get_encoding_operator(ksp_3d)  # Creates 3D operator\n\n# No need to specify is3D=true/false!","category":"section"},{"location":"high-level/nameddims/#Complete-Workflow-Examples","page":"Named Dimensions","title":"Complete Workflow Examples","text":"","category":"section"},{"location":"high-level/nameddims/#Example-1:-Basic-2D-Reconstruction","page":"Named Dimensions","title":"Example 1: Basic 2D Reconstruction","text":"using MriReconstructionToolbox\n\n# 1. Create phantom with names\nimg_true = NamedDimsArray{(:x, :y)}(shepp_logan(256, 256))\n\n# 2. Create sensitivity maps with names\nsmaps = NamedDimsArray{(:x, :y, :coil)}(\n    coil_sensitivities(256, 256, 8)\n)\n\n# 3. Create sampling pattern (regular array is fine)\npdf = VariableDensitySampling(GaussianDistribution(3), 3.0)\nmask = create_sampling_pattern(pdf, (256, 256))\n\n# 4. Simulate acquisition\nacq = AcquisitionInfo(image_size=(256, 256),\n                      sensitivity_maps=smaps,\n                      subsampling=mask)\nacq = simulate_acquisition(img_true, acq)\n\n# acq.kspace_data is now NamedDimsArray{(:kx, :ky, :coil)}\n\n# 5. Reconstruct\nimg_recon = reconstruct(acq, L1Wavelet2D(5e-3), verbose=false)\n\n# 6. Compare\ndimnames(img_recon)  # (:x, :y) - preserved from input\nnothing # hide","category":"section"},{"location":"high-level/nameddims/#Example-2:-Dynamic-Cardiac-Imaging","page":"Named Dimensions","title":"Example 2: Dynamic Cardiac Imaging","text":"# Create 2D+time data\nnt = 30\nimg_data = rand(ComplexF32, 256, 256, nt)\nimg_true = NamedDimsArray{(:x, :y, :cardiac_phase)}(img_data)\n\n# Sensitivity maps (same for all phases)\nsmaps = NamedDimsArray{(:x, :y, :coil)}(\n    coil_sensitivities(256, 256, 8)\n)\n\n# Create and simulate acquisition\npdf = VariableDensitySampling(GaussianDistribution(3), 3.0)\nmask = create_sampling_pattern(pdf, (256, 256))\nacq = AcquisitionInfo(image_size=(256, 256), \n                      sensitivity_maps=smaps,\n                      subsampling=mask)\nacq = simulate_acquisition(img_true, acq)\n\n# K-space is now (:kx, :ky, :coil, :cardiac_phase)\ndimnames(acq.kspace_data)\n\n# Reconstruct with temporal regularization\nimg_recon = reconstruct(acq, verbose=false)\n\n# Result preserves batch dimension\ndimnames(img_recon)  # (:x, :y, :cardiac_phase)\n\n# Easy to extract specific phases\nsystolic_phase = img_recon[cardiac_phase=5]\ndiastolic_phase = img_recon[cardiac_phase=20]\nnothing # hide","category":"section"},{"location":"high-level/nameddims/#Example-3:-Multi-Slice-3D","page":"Named Dimensions","title":"Example 3: Multi-Slice 3D","text":"# Multi-slice 2D acquisition\nnslices = 40\nksp_data = rand(ComplexF32, 256, 256, 8, nslices)\nksp = NamedDimsArray{(:kx, :ky, :coil, :z)}(ksp_data)\n\n# 3D sensitivity maps\nsmaps_data = coil_sensitivities(256, 256, 8)\nsmaps = NamedDimsArray{(:x, :y, :coil)}(smaps_data)\n\n# Create acquisition\nacq = AcquisitionInfo(ksp; sensitivity_maps=smaps)\n\n# Reconstruct\nimg = reconstruct(acq, verbose=false)\n\n# Result is (:x, :y, :z)\ndimnames(img)\n\n# Easy to access individual slices\nslice_10 = img[z=10]\nmiddle_slices = img[z=15:25]\nnothing # hide","category":"section"},{"location":"high-level/nameddims/#Advanced-Techniques","page":"Named Dimensions","title":"Advanced Techniques","text":"","category":"section"},{"location":"high-level/nameddims/#Dimension-Transformations","page":"Named Dimensions","title":"Dimension Transformations","text":"# Rename dimensions\nksp = NamedDimsArray{(:kx, :ky, :coil, :time)}(data)\n# Convert :time to :cardiac_phase\nimg = reconstruct(acq)  # Result has same batch dim names\n# Can't directly rename in NamedDims, but can rewrap\nimg_renamed = NamedDimsArray{(:x, :y, :cardiac_phase)}(parent(img))","category":"section"},{"location":"high-level/nameddims/#Combining-with-Regular-Arrays","page":"Named Dimensions","title":"Combining with Regular Arrays","text":"# Named array\nksp_named = NamedDimsArray{(:kx, :ky, :coil)}(...)\n\n# Extract regular array when needed\nksp_regular = parent(ksp_named)\nksp_regular = unname(ksp_named)  # Alternative way that works even if input is not NamedDimsArray\n\n# Some functions may require regular arrays\nresult = some_function(parent(ksp_named))\n\n# Re-wrap result\nresult_named = NamedDimsArray{(:x, :y)}(result)","category":"section"},{"location":"low-level/abstract_operators/#abstract_operators","page":"AbstractOperators.jl","title":"AbstractOperators.jl: Matrix-Free Linear Operators","text":"","category":"section"},{"location":"low-level/abstract_operators/#Why-Matrix-Free-Operators?","page":"AbstractOperators.jl","title":"Why Matrix-Free Operators?","text":"","category":"section"},{"location":"low-level/abstract_operators/#The-Matrix-Representation-Problem","page":"AbstractOperators.jl","title":"The Matrix Representation Problem","text":"In image processing and MRI reconstruction, operators are typically linear maps that can be theoretically represented as matrices. For example:\n\nFourier Transform: mathcalF mathbbC^N times M to mathbbC^N times M\nSubsampling: Gamma mathbbC^N times M to mathbbC^K (where K  N times M)\nSensitivity Encoding: mathcalS mathbbC^N times M to mathbbC^N times M times N_c\n\nIn traditional linear algebra, these would be represented as matrices A where:\n\ny = A x\n\nwhere x is the flattened input image and y is the flattened output.","category":"section"},{"location":"low-level/abstract_operators/#The-Good:-Rich-Algorithm-Ecosystem","page":"AbstractOperators.jl","title":"The Good: Rich Algorithm Ecosystem","text":"Matrix representations have significant advantages:\n\n‚úÖ Wide range of algorithms: Conjugate Gradient, LSQR, GMRES, and many other iterative solvers work with matrices.\n\n‚úÖ Theoretical foundation: Linear algebra theory provides convergence guarantees, preconditioning strategies, and optimality conditions.\n\n‚úÖ Composability: Operators can be easily composed (C = A cdot B), added (D = A + B), scaled, transposed, etc.\n\n‚úÖ Standard interface: Most numerical libraries understand matrices.","category":"section"},{"location":"low-level/abstract_operators/#The-Bad:-Computational-Inefficiency","page":"AbstractOperators.jl","title":"The Bad: Computational Inefficiency","text":"However, explicit matrix representations have critical drawbacks for image processing:\n\n‚ùå Memory explosion: An N times M image treated as a vector of length N cdot M requires a matrix of size (N cdot M) times (N cdot M) to represent an operator.\n\nExample: For a modest 256 times 256 image:\n\nFlattened vector: 256 times 256 = 65536 elements\nMatrix representation: 65536 times 65536 = 4294967296 elements\nMemory (Float64): ~34 GB just for one operator!\n\n‚ùå Loss of structure: Flattening an image discards its natural 2D/3D structure, making many operations less efficient.\n\n‚ùå Slow operations: Matrix-vector multiplication is mathcalO(N^2), while FFT on structured data is mathcalO(N log N).","category":"section"},{"location":"low-level/abstract_operators/#The-Solution:-Matrix-Free-Operators","page":"AbstractOperators.jl","title":"The Solution: Matrix-Free Operators","text":"Matrix-free operators are objects that:\n\nAct like matrices (support *, ', composition, addition)  \nWork directly on multi-dimensional arrays (no flattening needed)  \nImplement efficient algorithms internally (FFT, convolution, sparse indexing)  \nUse minimal memory (store only parameters, not full matrix)\n\nThis is exactly what AbstractOperators.jl provides.","category":"section"},{"location":"low-level/abstract_operators/#Introducing-AbstractOperators.jl","page":"AbstractOperators.jl","title":"Introducing AbstractOperators.jl","text":"AbstractOperators.jl is a Julia package that provides a comprehensive framework for matrix-free linear operators with:\n\nRich operator library: Fourier transforms, convolutions, finite differences, wavelets, and more\nMatrix-like interface: Supports *, ', +, ‚àò, and composition\nMulti-dimensional arrays: Works directly on images without flattening\nPerformance optimizations: Multi-threading, SIMD, operator fusion\nExtensibility: Easy to define custom operators","category":"section"},{"location":"low-level/abstract_operators/#Key-Features","page":"AbstractOperators.jl","title":"Key Features","text":"Feature Benefit\nMatrix-free Minimal memory footprint\nLazy composition Combines operators without intermediate allocations\nMulti-threading Automatic parallelization where supported\nType stability Full Julia type inference for performance","category":"section"},{"location":"low-level/abstract_operators/#Basic-Usage","page":"AbstractOperators.jl","title":"Basic Usage","text":"Note: Code blocks below are illustrative and not executed during docs build. To run them locally, activate a Julia environment and install the required packages:\n\nusing Pkg\n\n# Add the package from GitHub\nPkg.add(url=\"https://github.com/hakkelt/AbstractOperators.jl\")\nPkg.add(url=\"https://github.com/hakkelt/AbstractOperators.jl\", subdir=\"FFTWOperators\")\nPkg.add(url=\"https://github.com/hakkelt/AbstractOperators.jl\", subdir=\"WaveletOperators\")","category":"section"},{"location":"low-level/abstract_operators/#Simple-Operator-Example","page":"AbstractOperators.jl","title":"Simple Operator Example","text":"using AbstractOperators, FFTW, FFTWOperators, LinearAlgebra\n\nnx, ny = 64, 64\nF = ‚Ñ± = DFT(ComplexF32, (nx, ny)) # A 2D DFT operator for 64x64 images\n\nx = randn(ComplexF32, nx, ny);\ny = ‚Ñ± * x;  # Apply forward transform\ny == fft(x)  # Verify correctness\n\nx_back = F' * y;\nx_back == bfft(x)  # Verify correctness\n\nscale = 1 / (nx * ny) # Normalization factor that makes F unitary\nnorm(x - scale * x_back) / norm(x) < 1e-6 # Verify it's an approximate inverse","category":"section"},{"location":"low-level/abstract_operators/#Operator-Composition","page":"AbstractOperators.jl","title":"Operator Composition","text":"Operators can be composed naturally:\n\nmask = rand(Bool, nx, ny); mask[32-5:32+5, 32-5:32+5] .= true;  # Fully sample center\nsum(mask) # Count of sampled points\n\nŒì = GetIndex(zeros(ComplexF32, nx, ny), (mask,))\n\n‚Ñ±_sub = Œì * ‚Ñ± # Compose: subsampled Fourier transform\n\nx = randn(ComplexF32, nx, ny);\ny = ‚Ñ±_sub * x; # Apply the composition\ny == fft(x)[mask]  # Verify correctness","category":"section"},{"location":"low-level/abstract_operators/#Operator-Algebra","page":"AbstractOperators.jl","title":"Operator Algebra","text":"AbstractOperators supports rich algebraic operations:\n\nI_op = Eye(ComplexF32, (nx, ny)) # Identity operator\n\nA = 2 * ‚Ñ± # Scaling\n\nB = A + I_op # Addition of outputs\n\nd = randn(ComplexF32, nx, ny);\nD = DiagOp(d) # Diagonal scaling, i.e., element-wise multiplication with d\n\nC = D * B  # Composition / chaining of operators\n\nx = randn(ComplexF32, nx, ny);\ny = C * x; # Apply composed operator\ny == d .* (2 * fft(x) + x)  # Verify correctness","category":"section"},{"location":"low-level/abstract_operators/#Batch-Operations","page":"AbstractOperators.jl","title":"Batch Operations","text":"Operators can work on batched inputs (e.g., multi-coil data):\n\n# Sensitivity map operator (per-coil scaling)\nnc = 8  # 8 coils\nsmaps = randn(ComplexF32, nx, ny, nc)\nùíÆ = DiagOp(smaps)\n\n# Encoding operator: sensitivity * FFT\nùíú = ‚Ñ± * ùíÆ\n\n# Apply to multi-coil image\nx = randn(ComplexF32, nx, ny, nc)\nksp = ùíú * x\nprintln(\"Image size: $(size(x)), k-space size: $(size(ksp))\")","category":"section"},{"location":"low-level/abstract_operators/#Creating-Custom-Operators","page":"AbstractOperators.jl","title":"Creating Custom Operators","text":"You can easily define custom operators for domain-specific operations. Here's a minimal example:\n\nusing AbstractOperators\n\n# Define the operator struct\nstruct MyCustomLinOp{N,M,D,C} <: LinearOperator\n    dim_in::NTuple{M,Int}\n    dim_out::NTuple{N,Int}\n    # Add any additional fields needed for your operator\nend\n\n# Mandatory functions\n\n# 1. size: Return (codomain_size, domain_size)\nBase.size(L::MyCustomLinOp) = (L.dim_out, L.dim_in)\n\n# 2. domain_type: Return the element type of the input\nAbstractOperators.domain_type(::MyCustomLinOp{N,M,D,C}) where {N,M,D,C} = D\n\n# 3. codomain_type: Return the element type of the output\nAbstractOperators.codomain_type(::MyCustomLinOp{N,M,D,C}) where {N,M,D,C} = C\n\n# 4. fun_name: Return a string/symbol for display purposes\nAbstractOperators.fun_name(::MyCustomLinOp) = \"MyOp\"\n\n# 5. mul!: Forward operator (output, operator, input)\nfunction LinearAlgebra.mul!(y::AbstractArray, L::MyCustomLinOp, x::AbstractArray)\n    # Utility function to check if\n    #   - eltype(x) == domain_type(L)\n    #   - eltype(y) == codomain_type(L)\n    #   - size(x) == size(L, 2)\n    #   - size(y) == size(L, 1)\n    #   - x isa domain_storage_type(L)\n    #   - y isa codomain_storage_type(L)\n    AbstractOperators.check(y, L, x)\n    # Implement your forward operation here\n    # Example: y .= some_function(x)\n    return y\nend\n\n# 6. mul! for adjoint: Adjoint operator (output, adjoint_operator, input)\nfunction LinearAlgebra.mul!(y::AbstractArray, L::AdjointOperator{<:MyCustomLinOp}, x::AbstractArray)\n    AbstractOperators.check(y, L, x) # Utility function to check types and sizes\n    # Implement your adjoint operation here\n    # Example: y .= adjoint_function(x)\n    return y\nend\n\nKey points for custom operators:\n\nInherit from the right type: LinearOperator for linear maps, AbstractOperator for nonlinear\nImplement required interface: size, domain_type, codomain_type, fun_name, mul!\nImplement adjoint: For LinearOperator, also implement mul! for AdjointOperator\nTest correctness: Verify ‚ü®Lx, y‚ü© = ‚ü®x, L'y‚ü© for random inputs\n\nFor complete details on implementing custom operators, see the AbstractOperators.jl documentation.","category":"section"},{"location":"low-level/abstract_operators/#Operators-in-AbstractOperators.jl","page":"AbstractOperators.jl","title":"Operators in AbstractOperators.jl","text":"AbstractOperators.jl provides a rich library of pre-built operators, from which many are directly useful in MRI reconstruction:","category":"section"},{"location":"low-level/abstract_operators/#Transform-Operators","page":"AbstractOperators.jl","title":"Transform Operators","text":"DFT: Discrete Fourier Transform (via FFTWOperators.jl)\nDCT: Discrete Cosine Transform (via FFTWOperators.jl)\nRDFT: Real-to-complex FFT (via FFTWOperators.jl)\nWaveletOp: Wavelet transforms (via WaveletOperators.jl)\nNFFTOp: Non-uniform FFT (via NFFTOperators.jl)","category":"section"},{"location":"low-level/abstract_operators/#Linear-Operators","page":"AbstractOperators.jl","title":"Linear Operators","text":"Eye: Identity operator\nDiagOp: Diagonal operator (element-wise multiplication)\nMatrixOp: Wraps a regular matrix\nFiniteDiff: Finite difference (gradients)\nVariation: Total variation operator\nGetIndex: Subsampling/indexing operator\nZeroPad: Zero-padding operator","category":"section"},{"location":"low-level/abstract_operators/#Calculus","page":"AbstractOperators.jl","title":"Calculus","text":"Scale: Scalar multiplication\nCompose: Operator composition\nSum: Sum outputs of different operators applying to the same input\nBroadCast: Broadcasting operator ‚Äì repeats the output of an operator across specified dimensions\nReshape: Reshape arrays","category":"section"},{"location":"low-level/abstract_operators/#Nonlinear-Operators","page":"AbstractOperators.jl","title":"Nonlinear Operators","text":"Sigmoid, Tanh, Exp, Sin, Cos: Activation functions\nSoftMax, SoftPlus: Softmax and softplus","category":"section"},{"location":"low-level/abstract_operators/#Signal-Processing","page":"AbstractOperators.jl","title":"Signal Processing","text":"Conv: Convolution (via DSPOperators.jl)\nFilt: Filtering (via DSPOperators.jl)\nXcorr: Cross-correlation (via DSPOperators.jl)","category":"section"},{"location":"low-level/abstract_operators/#Integration-with-MriReconstructionToolbox","page":"AbstractOperators.jl","title":"Integration with MriReconstructionToolbox","text":"MriReconstructionToolbox.jl is built entirely on AbstractOperators.jl. All encoding operators (get_encoding_operator, get_fourier_operator, etc.) return AbstractOperators objects, giving you:\n\nSeamless integration: Use operators with any algorithm that supports the interface\nFlexibility: Extract and manipulate individual components of the encoding chain\nPerformance: Benefit from all AbstractOperators optimizations\nEasy debugging: Inspect and visualize operators at any stage\nExtensibility: Add custom operators to the reconstruction pipeline","category":"section"},{"location":"low-level/abstract_operators/#Extracting-Operators","page":"AbstractOperators.jl","title":"Extracting Operators","text":"# Get the full encoding operator\nùíú = get_encoding_operator(acq_info)\n\n# Or get individual components\n‚Ñ± = get_fourier_operator(acq_info)\nùíÆ = get_sensitivity_map_operator(acq_info)\n‚Ñ≥ = get_subsampling_operator(acq_info)\n\n# Manually compose them\nùíú_manual = ‚Ñ≥ * ‚Ñ± * ùíÆ\n\n# Both are equivalent\n@assert ùíú * x ‚âà ùíú_manual * x","category":"section"},{"location":"low-level/abstract_operators/#Custom-Reconstruction-Pipeline","page":"AbstractOperators.jl","title":"Custom Reconstruction Pipeline","text":"ùíÆ = MyCustomSensitivityMapOperator(...)\n‚Ñ± = get_fourier_operator(acq_info)\n‚Ñ≥ = get_subsampling_operator(acq_info)\nùíú = ‚Ñ≥ * ‚Ñ± * ùíÆ\n\n# Add custom regularization operator\nùí≤ = MyCustomWavelet(...)  # Your custom operator\n\n# Build optimization problem\nusing StructuredOptimization\nv = Variable(ùíú' * ksp)  # Initial guess\n\n# Solve custom problem\nxÃÇ, _ = @minimize ls(ùíú * v - ksp) + 0.01 * norm(ùí≤ * v, 1)","category":"section"},{"location":"low-level/abstract_operators/#Further-Reading","page":"AbstractOperators.jl","title":"Further Reading","text":"AbstractOperators.jl Documentation: https://hakkelt.github.io/AbstractOperators.jl/stable/\nCustom Operators Guide: https://hakkelt.github.io/AbstractOperators.jl/stable/custom/\nOperator Properties: Learn about operator traits and properties","category":"section"},{"location":"high-level/regularization/#Regularization","page":"Regularization","title":"Regularization","text":"Regularization is essential for reconstructing high-quality images from undersampled k-space data. This page explains the available regularization methods and how to use them.","category":"section"},{"location":"high-level/regularization/#Why-Regularization?","page":"Regularization","title":"Why Regularization?","text":"When k-space is undersampled (as in compressed sensing or parallel imaging), the reconstruction problem becomes ill-posed - there are many possible images that could have produced the observed data. Regularization adds prior knowledge about what \"good\" images look like to guide the reconstruction toward a unique, high-quality solution.","category":"section"},{"location":"high-level/regularization/#Understanding-the-Math","page":"Regularization","title":"Understanding the Math","text":"For those interested in the mathematical details, the reconstruction solves:\n\nminimize  (1/2)‚ÄñE¬∑x - y‚Äñ‚ÇÇ¬≤ + ‚àë·µ¢ Œª·µ¢¬∑R·µ¢(x)\n\nWhere:\n\nE is the encoding operator (Fourier + sensitivity + subsampling)\nx is the image to reconstruct\ny is the observed k-space data\n‚ÄñE¬∑x - y‚Äñ‚ÇÇ¬≤ is the data fidelity term\nR·µ¢(x) are the regularization terms\nŒª·µ¢ are the regularization parameters\n\nThe first term ensures the reconstruction is consistent with observed data. The regularization terms encode prior knowledge about image properties.","category":"section"},{"location":"high-level/regularization/#Available-Regularization-Methods","page":"Regularization","title":"Available Regularization Methods","text":"The code snippets in the following sections assume that MriReconstructionToolbox and MIRTjim are already imported. MIRTjim is a convenience wrapper around Plots.jl for displaying multidimensional images. Also, assume you have an AcquisitionInfo object acq representing your k-space data and acquisition settings for simulated Shepp-Logan phantom:\n\nusing MriReconstructionToolbox\nusing MIRTjim: jim\n\n# Simulate 2D acquisition\nx = shepp_logan(128, 128)\nx_noisy = x + 0.02f0 * randn(ComplexF32, 128, 128)\nsmaps = coil_sensitivities(128, 128, 8)\npdf = VariableDensitySampling(PolynomialDistribution(3), 4.0, 0.05)\npattern = create_sampling_pattern(pdf, (128, 128))\nacq_full = AcquisitionInfo(\n    is3D=false, \n    image_size=(128, 128), \n    subsampling=pattern, \n    sensitivity_maps=smaps\n)\ndata = simulate_acquisition(x_noisy, acq_full)\n\n# Simulate 3D acquisition\nx3d = shepp_logan(64, 64, 32)\nsmaps3d = coil_sensitivities(64, 64, 32, 8)\nsubsampling3d = create_sampling_pattern(\n    VariableDensitySampling(PolynomialDistribution(3), 4.0, 0.05), \n    (64, 64, 32)\n)\nacq3d = AcquisitionInfo(\n    image_size=(64, 64, 32), \n    sensitivity_maps=smaps3d,\n    subsampling=subsampling3d,\n)\ndata3d = simulate_acquisition(x3d, acq3d)\n\njim(x3d; title=\"Shepp-Logan Phantom (3D)\", size=(800,400))\nsavefig(\"shepp_logan_phantom_3d.png\"); nothing # hide\n\n(Image: shepp_logan_phantom_3d.png)","category":"section"},{"location":"high-level/regularization/#Image-Domain-Regularization","page":"Regularization","title":"Image Domain Regularization","text":"","category":"section"},{"location":"high-level/regularization/#Tikhonov-(L2)-Regularization","page":"Regularization","title":"Tikhonov (L2) Regularization","text":"The simplest form of regularization, penalizing large pixel values:\n\nWhen to use:\n\nNoise reduction without strong assumptions about image structure\nAs a baseline for comparison with other methods, especially for parallel imaging\nFast and simple regularization (it is computationally cheap and can be optimized with Conjugate Gradient)\n\nExample:\n\nimg‚ÇÅ = reconstruct(data, Tikhonov(1e-1), verbose=false)\nimg‚ÇÇ = reconstruct(data, Tikhonov(1e-6), verbose=false)\np1 = jim(img‚ÇÅ; title=\"Tikhonov Œª=1e-1\")\np2 = jim(img‚ÇÇ; title=\"Tikhonov Œª=1e-6\")\njim(p1, p2; layout=(1,2), size=(800,400))\nsavefig(\"tikhonov_regularization.png\"); nothing # hide\n\n(Image: tikhonov_regularization.png)","category":"section"},{"location":"high-level/regularization/#L1-Regularization","page":"Regularization","title":"L1 Regularization","text":"Promotes sparse images (many pixels close to zero):\n\nWhen to use:\n\nImages that are naturally sparse (e.g., angiography) and you want to suppress small values\n\nExample:\n\nimg‚ÇÅ = reconstruct(data, L1Image(1e-2), verbose=false)\nimg‚ÇÇ = reconstruct(data, L1Image(1e-5), verbose=false)\np1 = jim(img‚ÇÅ; title=\"L1Image Œª=1e-2\")\np2 = jim(img‚ÇÇ; title=\"L1Image Œª=1e-5\")\njim(p1, p2; layout=(1,2), size=(800,400))\nsavefig(\"l1image_regularization.png\"); nothing # hide\n\n(Image: l1image_regularization.png)","category":"section"},{"location":"high-level/regularization/#Wavelet-Domain-Regularization","page":"Regularization","title":"Wavelet Domain Regularization","text":"","category":"section"},{"location":"high-level/regularization/#2D-Wavelet-Sparsity","page":"Regularization","title":"2D Wavelet Sparsity","text":"Promotes sparsity in the wavelet domain:\n\nWhen to use:\n\nNatural images with structure at multiple scales\nMost MRI applications (anatomy has multi-scale features)\nStandard compressed sensing reconstruction\n\nParameters:\n\nŒª: Regularization strength (try 1e-3 to 1e-2)\nwavelet: Wavelet type (default: Daubechies, also try Haar, etc.)\nlevels: Number of decomposition levels (default: 4)\n\nExample:\n\nreg = L1Wavelet2D(1e-3)\nexample_img = rand(ComplexF32, 128, 128)\nop = get_operator(reg, example_img)\ntransformed = op * x_noisy\np1 = jim(transformed; title=\"Wavelet Coefficients\")\nimg = reconstruct(data, reg, verbose=false)\np2 = jim(img; title=\"L1Wavelet2D Reconstruction\")\njim(p1, p2; layout=(1,2), size=(800,400))\nsavefig(\"l1wavelet2d_regularization.png\"); nothing # hide\n\n(Image: l1wavelet2d_regularization.png)\n\nOptions for L1Wavelet2D:\n\nwavelet: Specify wavelet type (e.g., WT.haar, WT.db4)\nlevels: Number of decomposition levels (default: 4)\n\nreg_haar = L1Wavelet2D(1e-2; wavelet=WT.haar)\nop_haar = get_operator(reg_haar, example_img)\ntransformed_haar = op_haar * x_noisy\nimg_haar = reconstruct(data, reg_haar, verbose=false)\np1 = jim(transformed_haar; title=\"Haar Coefficients\")\np2 = jim(img_haar; title=\"Haar Reconstruction\")\n\nreg_level8 = L1Wavelet2D(1e-3; levels=8)\nop_level8 = get_operator(reg_level8, example_img)\ntransformed_level8 = op_level8 * x_noisy\nimg_level8 = reconstruct(data, reg_level8, verbose=false)\np3 = jim(transformed_level8; title=\"Level 8 Coefficients\")\np4 = jim(img_level8; title=\"Level 8 Reconstruction\")\njim(p1, p2, p3, p4; layout=(2,2), size=(800,700))\nsavefig(\"l1wavelet2d_options.png\"); nothing # hide\n\n(Image: l1wavelet2d_options.png)","category":"section"},{"location":"high-level/regularization/#3D-Wavelet-Sparsity","page":"Regularization","title":"3D Wavelet Sparsity","text":"For volumetric / multislice data, promotes sparsity in 3D wavelet domain:\n\nWhen to use:\n\n3D acquisitions or multi-slice 2D data\nWhen you want to exploit 3D structure\n\nExample:\n\nreg3d = L1Wavelet3D(1e-3)\n\nop = get_operator(reg3d, rand(ComplexF32, 64, 64, 32))\ntransformed = op * x3d\njim(abs.(transformed); title=\"3D Wavelet Coefficients\", size=(800,400))\nsavefig(\"l1wavelet3d_coefficients.png\"); nothing # hide\n\n(Image: l1wavelet3d_coefficients.png)","category":"section"},{"location":"high-level/regularization/#Total-Variation","page":"Regularization","title":"Total Variation","text":"","category":"section"},{"location":"high-level/regularization/#2D-Total-Variation","page":"Regularization","title":"2D Total Variation","text":"Promotes piecewise-constant images by penalizing rapid changes:\n\nWhen to use:\n\nImages with sharp edges and flat regions\nBrain imaging with gray/white matter boundaries\nWhen you want strong edge preservation\n\nExample:\n\nreg = TotalVariation2D(1e-3)\nop = get_operator(reg, example_img)\ntransformed = op * x_noisy\nimg = reconstruct(data, reg, verbose=false)\np1 = jim(transformed[:,:,1]; title=\"Œîx Coefficients\")\np2 = jim(transformed[:,:,2]; title=\"Œîy Coefficients\")\np3 = jim(img; title=\"TotalVariation2D Reconstruction\")\njim(p1, p2, p3; layout=(1, 3), size=(900,250))\nsavefig(\"totalvariation2d_coefficients.png\"); nothing # hide\n\n(Image: totalvariation2d_coefficients.png)\n\nPractical tip: TV can create a \"cartoon-like\" appearance. Use lower Œª values (1e-4 to 5e-3) to preserve texture.","category":"section"},{"location":"high-level/regularization/#3D-Total-Variation","page":"Regularization","title":"3D Total Variation","text":"For volumetric / multislice data, promotes piecewise-constant structure in 3D:","category":"section"},{"location":"high-level/regularization/#Temporal-Regularization","page":"Regularization","title":"Temporal Regularization","text":"","category":"section"},{"location":"high-level/regularization/#Temporal-Fourier-Sparsity","page":"Regularization","title":"Temporal Fourier Sparsity","text":"For dynamic imaging, promotes sparsity in the temporal Fourier domain:\n\nWhen to use:\n\nDynamic or cine imaging\nCardiac MRI\nDCE-MRI (dynamic contrast enhanced)\nWhen motion is periodic or smoothly varying\n\nExample:\n\nimg = reconstruct(acq, TemporalFourier(1e-2, time_dim=4))\n\nPractical tip: This works best when temporal changes are smooth or periodic. For irregular motion, consider low-rank methods instead.","category":"section"},{"location":"high-level/regularization/#Low-Rank-Regularization","page":"Regularization","title":"Low-Rank Regularization","text":"","category":"section"},{"location":"high-level/regularization/#Nuclear-Norm","page":"Regularization","title":"Nuclear Norm","text":"Promotes low-rank structure in dynamic data:\n\nWhen to use:\n\nDynamic imaging with temporal correlations\nBackground suppression in DCE-MRI\nData with strong spatiotemporal correlations\nWhen images share common features across time\n\nExample:\n\n# Dynamic series with low-rank structure\nimg = reconstruct(acq_dynamic, LowRank(1e-1))\n\nPractical tip: Low-rank methods can be computationally expensive. Use for datasets where temporal correlations are strong.","category":"section"},{"location":"high-level/regularization/#Combining-Multiple-Regularizers","page":"Regularization","title":"Combining Multiple Regularizers","text":"You can combine multiple regularization terms to exploit different image properties simultaneously:\n\n# Comprehensive regularization for dynamic imaging\nreg = (\n    L1Wavelet2D(5e-3),      # Spatial sparsity\n    TotalVariation2D(1e-3),  # Edge preservation\n    TemporalFourier(2e-2)    # Temporal smoothness\n)\nimg = reconstruct(acq_dynamic, reg)\n\nWhen to combine:\n\nWavelet + TV: Exploit both multi-scale structure and edge preservation\nSpatial + Temporal: Regularize both space and time dimensions\nMultiple spatial regularizers: When images have complex structure","category":"section"},{"location":"high-level/regularization/#Choosing-Regularization-Parameters","page":"Regularization","title":"Choosing Regularization Parameters","text":"The regularization parameter Œª controls the trade-off between data fidelity and regularization:\n\nToo small (Œª ‚Üí 0): Noisy, artifacts remain\nToo large (Œª ‚Üí ‚àû): Over-smoothed, loss of detail\nJust right: Balance between noise/artifact suppression and detail preservation","category":"section"},{"location":"high-level/regularization/#Practical-Guidelines","page":"Regularization","title":"Practical Guidelines","text":"Starting values by regularization type:\n\nTikhonov: 1e-5 to 1e-3\nL1Image: 1e-4 to 1e-2\nL1Wavelet: 1e-3 to 1e-2\nTotalVariation: 1e-4 to 5e-3\nTemporalFourier: 1e-2 to 1e-1\nLowRank: 1e-2 to 1\n\nAdjustment strategy:\n\nStart with the suggested value\nIf too noisy/aliased ‚Üí increase Œª\nIf too smooth/blurry ‚Üí decrease Œª\nTypical range: adjust by factors of 2-5","category":"section"},{"location":"high-level/regularization/#MriReconstructionToolbox.Tikhonov","page":"Regularization","title":"MriReconstructionToolbox.Tikhonov","text":"Tikhonov(Œª)\n\nCreate a Tikhonov regularization term with parameter Œª.\n\nThe regularization term is given by Œª¬≤‚Äñx‚Äñ‚ÇÇ¬≤, or ‚ÄñŒì .* x‚Äñ‚ÇÇ¬≤ if Œª is an array Œì of the same size as x.\n\nArguments\n\nŒª: Regularization parameter, can be a scalar or an array of the same size as x.\n\nNotes\n\nThis regularization term is also known as L2 regularization or ridge regression.\nThe squared parameter Œª¬≤ is used in the formulation to align with common conventions in\n\nTikhonov regularization literature.\n\n\n\n\n\n","category":"type"},{"location":"high-level/regularization/#MriReconstructionToolbox.L1Image","page":"Regularization","title":"MriReconstructionToolbox.L1Image","text":"L1Image(Œª)\n\nCreate a L1 image regularization term with parameter Œª. The regularization term is given by Œª‚Äñx‚Äñ‚ÇÅ, or ‚ÄñŒì .* x‚Äñ‚ÇÅ if Œª is an array Œì of the same size as x.\n\nArguments\n\nŒª: Regularization parameter, can be a scalar or an array of the same size as x.\n\n\n\n\n\n","category":"type"},{"location":"high-level/regularization/#MriReconstructionToolbox.L1Wavelet2D","page":"Regularization","title":"MriReconstructionToolbox.L1Wavelet2D","text":"L1Wavelet2D(Œª; wavelet=WT.db2, levels=2)\n\nCreate a L1 wavelet regularization term for 2D images with parameter Œª. The regularization term is given by Œª‚Äñùí≤x‚Äñ‚ÇÅ, where ùí≤ is the 2D wavelet transform operator. The wavelet and levels parameters control the type of wavelet and the number of decomposition levels used in the transform.\n\nArguments\n\nŒª: Regularization parameter, can be a scalar or an array of the same size as x.\nwavelet: (optional) Type of wavelet to use, specified as a WT.Wavelet. Default is WT.db2 (Daubechies 2).\nlevels: (optional) Number of decomposition levels in the wavelet transform. Default is 2.\n\n\n\n\n\n","category":"type"},{"location":"high-level/regularization/#MriReconstructionToolbox.L1Wavelet3D","page":"Regularization","title":"MriReconstructionToolbox.L1Wavelet3D","text":"L1Wavelet3D(Œª; wavelet=WT.db2, levels=2)\n\nCreate a L1 wavelet regularization term for 3D images with parameter Œª. The regularization term is given by Œª‚Äñùí≤x‚Äñ‚ÇÅ, where ùí≤ is the 3D wavelet transform operator. The wavelet and levels parameters control the type of wavelet and the number of decomposition levels used in the transform.\n\nArguments\n\nŒª: Regularization parameter, can be a scalar or an array of the same size as x.\nwavelet: (optional) Type of wavelet to use, specified as a WT.Wavelet. Default is WT.db2 (Daubechies 2).\nlevels: (optional) Number of decomposition levels in the wavelet transform. Default is 2.\n\n\n\n\n\n","category":"type"},{"location":"high-level/regularization/#MriReconstructionToolbox.TotalVariation2D","page":"Regularization","title":"MriReconstructionToolbox.TotalVariation2D","text":"TotalVariation2D(Œª)\n\nCreate a Total Variation regularization term for 2D images with parameter Œª. The regularization term is given by Œª‚ÄñŒîx‚Äñ_{2,1}, where Œî is the 2D finite difference operator computing gradients along the two spatial dimensions.\n\nArguments\n\nŒª: Regularization parameter, must be a scalar.\n\n\n\n\n\n","category":"type"},{"location":"high-level/regularization/#MriReconstructionToolbox.TotalVariation3D","page":"Regularization","title":"MriReconstructionToolbox.TotalVariation3D","text":"TotalVariation3D(Œª)\n\nCreate a Total Variation regularization term for 3D images with parameter Œª. The regularization term is given by Œª‚ÄñŒîx‚Äñ_{2,1}, where Œî is the 3D finite difference operator computing gradients along the three spatial dimensions.\n\nArguments\n\nŒª: Regularization parameter, must be a scalar.\n\n\n\n\n\n","category":"type"},{"location":"high-level/regularization/#MriReconstructionToolbox.TemporalFourier","page":"Regularization","title":"MriReconstructionToolbox.TemporalFourier","text":"TemporalFourier(Œª; time_dim=nothing)\n\nCreate a temporal Fourier regularization term with parameter Œª. The regularization term is given by Œª‚Äñùìï‚Çú{x}‚Äñ‚ÇÅ, where ùìï‚Çú is the discrete Fourier transform along the temporal dimension specified by time_dim. If time_dim is not provided, it will be inferred as the dimension named :time if x is a NamedDimsArray.\n\nArguments\n\nŒª: Regularization parameter, can be a scalar or an array of the same size as x.\ntime_dim: (optional) Dimension along which to apply the Fourier transform. Can be an Integer (1-based index)\n\nor a Symbol (dimension name). If not provided, it will be inferred as the dimension named :time if x is a NamedDimsArray.\n\n\n\n\n\n","category":"type"},{"location":"high-level/regularization/#MriReconstructionToolbox.LowRank","page":"Regularization","title":"MriReconstructionToolbox.LowRank","text":"LowRank(Œª; time_dim=nothing)\n\nCreate a low-rank regularization term with parameter Œª. The regularization term is given by Œª‚Äñùìß‚Äñ_*, where ùìß is the Casorati matrix formed by unfolding the input variable x along the temporal dimension specified by time_dim. If time_dim is not provided, it will be inferred as the dimension named :time if x is a NamedDimsArray.\n\nArguments\n\nŒª: Regularization parameter, can be a scalar or an array of the same size as x.\ntime_dim: (optional) Dimension along which to form the Casorati matrix. Can be an Integer (1-based index)\n\nor a Symbol (dimension name). If not provided, it will be inferred as the dimension named :time if x is a NamedDimsArray.\n\nNotes:\n\nThe nuclear norm ‚Äñùìß‚Äñ_* is the sum of the singular values of the matrix ùìß.\nThe Casorati matrix is formed by reshaping x such that the specified time_dim becomes the second dimension,\n\nand all other dimensions before it are reshaped into columns (first dimension), while dimensions after it are treated as batch dimensions.\n\n\n\n\n\n","category":"type"},{"location":"high-level/regularization/#MriReconstructionToolbox.RankLimit","page":"Regularization","title":"MriReconstructionToolbox.RankLimit","text":"RankLimit(max_rank; time_dim=nothing)\n\nCreate a rank limit regularization term that constrains the rank of the Casorati matrix formed by unfolding the input variable x along the temporal dimension specified by time_dim. The rank of the Casorati matrix will be limited to max_rank. If time_dim is not provided, it will be inferred as the dimension named :time if x is a NamedDimsArray.\n\nArguments\n\nmax_rank: Maximum allowed rank for the Casorati matrix.\ntime_dim: (optional) Dimension along which to form the Casorati matrix. Can be an Integer (1-based index)\n\nor a Symbol (dimension name). If not provided, it will be inferred as the dimension named :time if x is a NamedDimsArray.\n\nNotes:\n\nThe nuclear norm ‚Äñùìß‚Äñ_* is the sum of the singular values of the matrix ùìß.\nThe Casorati matrix is formed by reshaping x such that the specified time_dim becomes the second dimension,\n\nand all other dimensions before it are reshaped into columns (first dimension), while dimensions after it are treated as batch dimensions.\n\n\n\n\n\n","category":"type"},{"location":"low-level/proximal_operators/#ProximalOperators.jl-Summary","page":"ProximalOperators.jl","title":"ProximalOperators.jl Summary","text":"This page gives a quick overview of the ProximalOperators.jl package, which supplies a large catalog of convex (and some nonconvex) function objects together with their proximal operators (and gradients when available). These building blocks can be used by (ProximalAlgorithms.jl) and by the reconstruction routines in this toolbox to express regularization terms and constraints.","category":"section"},{"location":"low-level/proximal_operators/#Goal","page":"ProximalOperators.jl","title":"Goal","text":"Provide efficient, composable implementations of ( f: \\mathbb{C}^n \\to \\mathbb{R}\\cup{+\\infty} ) with:\n\nFast evaluation of value f(x)\n(Optionally) gradient evaluation gradient(f, x) / gradient!(y, f, x)\nProximal mapping prox(f, x, Œ≥) / in-place prox!(y, f, x, Œ≥)\nTraits advertising structural properties (convexity, separability, smoothness) exploited by algorithms.","category":"section"},{"location":"low-level/proximal_operators/#Most-Common-Norm-/-Regularization-Functions","page":"ProximalOperators.jl","title":"Most Common Norm / Regularization Functions","text":"The following constructors (all exported) cover the majority of regularization needs in MRI reconstruction and sparse inverse problems:\n\nFunction Description Typical Use\nNormL0(Œª) Counts nonzeros (scaled) Hard sparsity (often surrogate)\nNormL1(Œª) ( Œª|x|_1 ) (weighted variant) Soft sparsity / wavelets\nNormL2(Œª) ( Œª|x|_2 ) Magnitude penalization / normalization\nSqrNormL2(Œª) ( \\tfrac{Œª}{2}|x|_2^2 ) (ridge) Tikhonov / quadratic penalization\nNormL21(Œª) Group sparsity (sum of L2 norms over groups) Multidimensional total variation\nNormLinf(Œª) ( Œª|x|_\\infty ) Robust range control\nElasticNet(Œª1, Œª2) ( Œª1|x|1 + \\tfrac{Œª2}{2}|x|2^2 ) Combined sparsity + shrinkage\nTotalVariation1D(Œª) Discrete TV along 1D axis Temporal / 1D smoothing\nNuclearNorm(Œª) ( Œª|X|_* ) (sum singular values) Low-rank models (dynamic MRI)\nCubeNormL2(Œª) ( Œª|x|_2^3 ) Specialized smoothing\nIndBox(lower, upper) Indicator of box constraints Hard constraints on values\nIndNonnegative() Indicator of non-negativity Enforce non-negative solutions\nIndBallRank(r) Indicator of rank ‚â§ r Hard low-rank constraints\n\n(See the full list in the upstream documentation for additional indicators, losses, and composite penalties.)","category":"section"},{"location":"low-level/proximal_operators/#Quick-Usage-Examples","page":"ProximalOperators.jl","title":"Quick Usage Examples","text":"using ProximalOperators\nx = randn(10)\n\n# L1 norm\nf1 = NormL1(0.5)\nval1 = f1(x)\n# Prox (soft-threshold)\ny1, fy1 = prox(f1, x, 0.2)\n\n# Elastic net\nfen = ElasticNet(0.3, 0.8)\nval_en = fen(x)\ny_en, fy_en = prox(fen, x, 0.5)\n\n# Group sparsity (split into groups of size 2)\n# NormL21 expects a partition; simplest is reshape\nxg = reshape(randn(12), 2, 6)  # 6 groups of length 2\nfg = NormL21(0.4)\nval_g = fg(xg)\nyg, fyg = prox(fg, xg, 0.3)\n\nprintln(\"L1 value: \", val1)\nprintln(\"Elastic net prox value: \", fy_en)\nprintln(\"Group sparsity prox value: \", fyg)","category":"section"},{"location":"low-level/proximal_operators/#Implementing-a-Custom-Norm-(Minimal-Example)","page":"ProximalOperators.jl","title":"Implementing a Custom Norm (Minimal Example)","text":"Below is a minimal implementation of L2-norm:\n\nf(x) = x_2 = sqrtsum_i=1^n x_i^2\n\nKey steps:\n\nDefine a struct holding parameters.\nAdd trait methods (used by StructuredOptimization.jl to parse terms for algorithms).\nDefine call (f)(x) for value.\nImplement gradient!(y, f, x) if differentiable (not here).\nImplement prox!(y, f, x, Œ≥) (and optionally for complex or array Œ≥).\n\nimport ProximalCore: is_proximable, is_separable, is_convex, is_locally_smooth, prox!, gradient!\nusing ProximalOperators\nusing LinearAlgebra: norm\n\nstruct MyNormL2{R}\n    lambda::R\n    function MyNormL2{R}(lambda::R) where R\n        if lambda < 0\n            error(\"parameter Œª must be nonnegative\")\n        else\n            new(lambda)\n        end\n    end\nend\n\nis_convex(f::Type{<:MyNormL2}) = true\nis_positively_homogeneous(f::Type{<:MyNormL2}) = true\nis_locally_smooth(f::Type{<:MyNormL2}) = true\n\nMyNormL2(lambda::R=1) where R = MyNormL2{R}(lambda)\n\n(f::MyNormL2)(x) = f.lambda * norm(x)\n\nfunction prox!(y, f::MyNormL2, x, gamma)\n    normx = norm(x)\n    scale = max(0, 1 - f.lambda * gamma / normx)\n    for i in eachindex(x)\n        y[i] = scale*x[i]\n    end\n    return f.lambda * scale * normx\nend\n\nfunction gradient!(y, f::MyNormL2, x)\n    fx = norm(x) # Value of f, without lambda\n    if fx == 0\n        y .= 0\n    else\n        y .= (f.lambda / fx) .* x\n    end\n    return f.lambda * fx\nend\n\n# Test the custom norm\nx = randn(8)\nf_custom = MyNormL2(0.7)\nval_before = f_custom(x)\nyc, val_after = prox(f_custom, x, 0.4)\nprintln(\"Custom norm value (before): \", val_before)\nprintln(\"Custom norm value (after prox): \", val_after)","category":"section"},{"location":"low-level/proximal_operators/#See-Also","page":"ProximalOperators.jl","title":"See Also","text":"Upstream docs: https://juliafirstorder.github.io/ProximalOperators.jl/stable/\nAlgorithm layer: ProximalAlgorithms.jl\nThis toolbox high-level regularization page: Regularization","category":"section"},{"location":"high-level/reconstruction/#reconstruction","page":"Reconstruction","title":"Image Reconstruction","text":"The reconstruct function is the primary high-level interface for MRI image reconstruction from k-space data. It handles both direct (adjoint-based) and iterative reconstruction with regularization, with automatic problem decomposition and performance optimization.","category":"section"},{"location":"high-level/reconstruction/#API-Reference","page":"Reconstruction","title":"API Reference","text":"","category":"section"},{"location":"high-level/reconstruction/#Basic-Usage","page":"Reconstruction","title":"Basic Usage","text":"The simplest reconstruction requires only k-space data:\n\nusing MriReconstructionToolbox\n\n# Create k-space data\nksp = rand(ComplexF32, 128, 128, 8)\nacq = AcquisitionInfo(ksp; is3D=false)\n\n# Direct reconstruction (adjoint of encoding operator)\nx_direct = reconstruct(acq)\nprintln(\"Reconstructed image size: \", size(x_direct))","category":"section"},{"location":"high-level/reconstruction/#Reconstruction-Workflow","page":"Reconstruction","title":"Reconstruction Workflow","text":"","category":"section"},{"location":"high-level/reconstruction/#1.-Direct-Reconstruction-(No-Regularization)","page":"Reconstruction","title":"1. Direct Reconstruction (No Regularization)","text":"When no regularization is specified, reconstruct performs a direct reconstruction using the adjoint of the encoding operator:\n\n# Fully sampled data\nksp_full = rand(ComplexF32, 64, 64, 4)\nsmaps = rand(ComplexF32, 64, 64, 4)\nacq_full = AcquisitionInfo(ksp_full; is3D=false, sensitivity_maps=smaps)\n\n# Direct reconstruction: x = ùíú' * y\nx_direct = reconstruct(acq_full)\nprintln(\"Direct reconstruction completed\")\nprintln(\"Output type: \", typeof(x_direct))\n\nThis is equivalent to:\n\nhatx = mathcalA^H y\n\nwhere mathcalA is the encoding operator and y is the k-space data.","category":"section"},{"location":"high-level/reconstruction/#2.-Iterative-Reconstruction-with-Regularization","page":"Reconstruction","title":"2. Iterative Reconstruction with Regularization","text":"For undersampled data, add regularization to solve:\n\nmin_x frac12mathcalAx - y_2^2 + sum_i lambda_i R_i(x)\n\n# Undersampled acquisition\nmask = rand(Bool, 64, 64)\nmask[25:40, 25:40] .= true  # Fully sample center\nacq_under = AcquisitionInfo(\n    nothing;\n    is3D=false,\n    image_size=(64, 64),\n    subsampling=mask,\n    sensitivity_maps=smaps\n)\n\n# Simulate undersampled data\nphantom = rand(ComplexF32, 64, 64)\ndata = simulate_acquisition(phantom, acq_under)\n\n# Reconstruct with L2 regularization\nx_tikhonov = reconstruct(data, Tikhonov(0.01); maxit=20, verbose=false)\nprintln(\"Tikhonov reconstruction completed\")","category":"section"},{"location":"high-level/reconstruction/#Configuration-Control","page":"Reconstruction","title":"Configuration Control","text":"The Config struct centralizes reconstruction parameters. You can pass configuration either as a Config object or as keyword arguments. It can make easy to pass common options together, while still allowing overrides via keywords.\n\n# Method 1: Keyword arguments\nx1 = reconstruct(data; maxit=50, tol=1e-5, verbose=false)\nnothing # hide\n\n# Method 2: Config object\nconfig = Config(maxit=50, tol=1e-5, verbose=false)\nx2 = reconstruct(data; config=config)\nnothing # hide\n\n# Method 3: Override config fields with keywords\nconfig_base = Config(maxit=100, verbose=false)\nx3 = reconstruct(data; config=config_base, maxit=25, verbose=false)  # Uses maxit=25\nnothing # hide","category":"section"},{"location":"high-level/reconstruction/#Important-Configuration-Options","page":"Reconstruction","title":"Important Configuration Options","text":"","category":"section"},{"location":"high-level/reconstruction/#Iteration-Control","page":"Reconstruction","title":"Iteration Control","text":"# Basic iteration parameters\nConfig(\n    maxit=100,     # Maximum iterations\n    tol=1e-4,      # Stopping tolerance\n    freq=10,       # Print progress every 10 iterations\n    verbose=true   # Enable logging\n)","category":"section"},{"location":"high-level/reconstruction/#Performance-Options","page":"Reconstruction","title":"Performance Options","text":"# Threading and performance\nConfig(\n    threaded=true,                          # Enable multi-threading\n    exact_opnorm=false,                     # Fast operator norm estimation\n    disable_problem_decomposition=false,    # Enable automatic decomposition\n    disable_operator_normalization=false    # Enable operator normalization\n)","category":"section"},{"location":"high-level/reconstruction/#Normalization","page":"Reconstruction","title":"Normalization","text":"# Data scaling strategies\nconfig_bart = Config(normalization=BartScaling())\nconfig_none = Config(normalization=NoScaling())\nnothing # hide","category":"section"},{"location":"high-level/reconstruction/#Algorithm-Selection","page":"Reconstruction","title":"Algorithm Selection","text":"Choose optimization algorithms based on your problem:\n\n# Single algorithm\nx_cg = reconstruct(data, Tikhonov(0.01), FISTA(); maxit=30, verbose=false)\nnothing # hide\n\n# Tuple of algorithms (tries in order until convergence)\nx_auto = reconstruct(\n    data,\n    Tikhonov(0.01),\n    (CG(), FISTA(), ADMM());\n    maxit=50,\n    verbose=false\n)\nnothing # hide\n\nCommon algorithms:\n\nCG: Conjugate Gradient - best for quadratic problems (Tikhonov regularization)\nFISTA: Fast Iterative Shrinkage-Thresholding - for L1 regularization\nADMM: Alternating Direction Method of Multipliers - for composite regularization\n\nSee Optimization Algorithms for detailed information.","category":"section"},{"location":"high-level/reconstruction/#Multiple-Regularization-Terms","page":"Reconstruction","title":"Multiple Regularization Terms","text":"Combine multiple regularization terms for advanced reconstruction:\n\n# Wavelet sparsity + Total Variation\nx_composite = reconstruct(\n    data,\n    (L1Wavelet2D(0.005), TotalVariation2D(0.002));\n    maxit=50,\n    verbose=false\n)\nnothing # hide\n\nSee Regularization for available regularization methods.","category":"section"},{"location":"high-level/reconstruction/#Initial-Guess","page":"Reconstruction","title":"Initial Guess","text":"Provide a custom initial estimate:\n\n# Use direct reconstruction as initial guess\nx_init = reconstruct(data; verbose=false)\n\n# Refine with regularization\nx_refined = reconstruct(\n    data,\n    L1Wavelet2D(0.005);\n    x‚ÇÄ=x_init,\n    maxit=30,\n    verbose=false\n)\nnothing # hide","category":"section"},{"location":"high-level/reconstruction/#Advanced-Features","page":"Reconstruction","title":"Advanced Features","text":"","category":"section"},{"location":"high-level/reconstruction/#Operator-Normalization","page":"Reconstruction","title":"Operator Normalization","text":"By default, the encoding operator is normalized for better convergence:\n\n# Standard (normalized operator)\nx_norm = reconstruct(data, Tikhonov(0.01); maxit=20, verbose=false)\n\n# Disable normalization\nx_unnorm = reconstruct(\n    data,\n    Tikhonov(0.01);\n    disable_operator_normalization=true,\n    maxit=20,\n    verbose=false\n)\nprintln(\"Both reconstructions completed\")\n\nOperator normalization typically improves convergence by ensuring the encoding operator has unit norm, which helps algorithms choose better stepsizes.","category":"section"},{"location":"high-level/reconstruction/#Normal-Operator-Optimization","page":"Reconstruction","title":"Normal Operator Optimization","text":"For least-squares problems, reconstruct can exploit efficient normal operator implementations:\n\n# Standard optimization (enabled by default)\nconfig_opt = Config(disable_normalop_optimization=false)\n\n# Disable for debugging\nconfig_noopt = Config(disable_normalop_optimization=true)\nnothing # hide\n\nWhen enabled, instead of computing mathcalAx - y_2^2 directly, it computes mathcalA^HmathcalAx - mathcalA^Hy_2^2, which can be more efficient when mathcalA^HmathcalA has an optimized implementation.","category":"section"},{"location":"high-level/reconstruction/#Output-Scaling","page":"Reconstruction","title":"Output Scaling","text":"Control whether the output is scaled back to the original data range:\n\n# Standard (output is inverse-scaled)\nx_scaled = reconstruct(data, Tikhonov(0.01); maxit=20, verbose=false)\n\n# Keep scaled output\nx_unscaled = reconstruct(\n    data,\n    Tikhonov(0.01);\n    disable_inverse_scale_output=true,\n    maxit=20,\n    verbose=false\n)\n\nprintln(\"Scaled max: \", maximum(abs, x_scaled))\nprintln(\"Unscaled max: \", maximum(abs, x_unscaled))","category":"section"},{"location":"high-level/reconstruction/#Problem-Decomposition","page":"Reconstruction","title":"Problem Decomposition","text":"For multi-dimensional data (e.g., 2D+time, multi-slice), reconstruct automatically decomposes the problem over independent dimensions:\n\n# Multi-slice 2D data\nnx, ny, nslices, nc = 32, 32, 5, 4\nksp_ms = rand(ComplexF32, nx, ny, nc, nslices)\nsmaps_ms = rand(ComplexF32, nx, ny, nc, nslices)\n\nacq_ms = AcquisitionInfo(ksp_ms; is3D=false, sensitivity_maps=smaps_ms)\n\n# Automatically decomposes over slice dimension\nx_slices = reconstruct(acq_ms; maxit=10, verbose=false)\nprintln(\"Reconstructed slices: \", size(x_slices))\n\nThe decomposition:\n\nIdentifies batch dimensions not affected by Fourier transforms or regularization\nReconstructs each batch element independently\nUtilizes multiple CPU cores for parallel execution\nCombines results into a single output array\n\nTo disable decomposition (e.g., for debugging):\n\nx_no_decomp = reconstruct(\n    acq_ms;\n    disable_problem_decomposition=true,\n    maxit=10,\n    verbose=false\n)\nprintln(\"Sequential reconstruction completed\")\n\nSee Problem Decomposition for details.","category":"section"},{"location":"high-level/reconstruction/#Custom-Progress-Logging","page":"Reconstruction","title":"Custom Progress Logging","text":"Replace the default logging function:\n\n# Custom print function\nmessages = String[]\ncustom_print(args...) = push!(messages, string(args...))\n\nconfig_custom = Config(\n    printfunc=custom_print,\n    verbose=true\n)\n\nx_custom = reconstruct(data, Tikhonov(0.01); config=config_custom, maxit=5)\nprintln(\"Captured \", length(messages), \" log messages\")\nprintln(\"First message: \", messages[1])","category":"section"},{"location":"high-level/reconstruction/#Named-Dimensions-Support","page":"Reconstruction","title":"Named Dimensions Support","text":"reconstruct preserves NamedDimsArray metadata:\n\nusing NamedDims\n\n# Create named k-space data\nksp_named = NamedDimsArray{(:kx, :ky, :coil)}(\n    rand(ComplexF32, 64, 64, 4)\n)\nsmaps_named = NamedDimsArray{(:x, :y, :coil)}(\n    rand(ComplexF32, 64, 64, 4)\n)\n\nacq_named = AcquisitionInfo(ksp_named; sensitivity_maps=smaps_named)\nx_named = reconstruct(acq_named; verbose=false)\n\nprintln(\"Output dimensions: \", dimnames(x_named))\n\nSee Named Dimensions for more information.","category":"section"},{"location":"high-level/reconstruction/#MriReconstructionToolbox.reconstruct","page":"Reconstruction","title":"MriReconstructionToolbox.reconstruct","text":"reconstruct(\n\tacq_data::AcquisitionInfo;\n\tregularization::Union{Regularization, Tuple{Vararg{Regularization}}}=(),\n\talgorithm=(CG(;maxit=20), FISTA(;maxit=50), ADMM(;maxit=100)),\n\tthreaded::Bool=true)\n\nPerforms MRI reconstruction from k-space data using the specified regularization, and optimization algorithm.\n\nArguments\n\nacq_data::AcquisitionInfo: The acquisition information containing k-space data, sensitivity maps, and other parameters.\nregularization::Union{Regularization, Tuple{Vararg{Regularization}}}: The regularization term(s) to use (default is no regularization).\nalgorithm: The optimization algorithm(s) to use (default is a tuple of CG, FISTA, and ADMM with specified max iterations).\nx‚ÇÄ::Union{Nothing,AbstractArray}=nothing: Optional initial guess for the image (default is ùíú' * y).\nnormalization::Normalization = BartScaling(): scaling applied to operators/data\ntol::Float64 = 1e-4: stopping tolerance for iterative algorithms\nmaxit::Int = 100: maximum iterations for the chosen solver\nfreq::Union{Nothing,Int} = nothing: progress print frequency (iterations)\nverbose::Bool = true: enable/disable logging output\nthreaded::Bool = (Threads.nthreads() > 1): enable threaded execution when available\nexact_opnorm::Bool = false: use exact operator norm for stepsize estimation\ndecomposition_executor::Union{Nothing,ReconstructionExecutor} = nothing: override executor for decomposition\ndisable_inverse_scale_output::Bool = false: skip rescaling the final output\ndisable_normalop_optimization::Bool = false: disable normal-operator optimizations\ndisable_problem_decomposition::Bool = false: disable automatic problem decomposition\ndisable_operator_normalization::Bool = false: disable operator normalization\nprintfunc::Function = println: custom logging function\n\nReturns\n\nThe reconstructed image (NamedDimsArray if input is NamedDimsArray, otherwise standard Array).\n\nNotes\n\nNormalop Optimization\n\nIf disable_normalop_optimization is false, the function uses normalop_ls for efficiency when appropriate.\nIt should not change the result of the reconstruction, but it changes the reported value of consistency term.\nTo understand this, one can think of the optimization problem as minimizing\n\n|| ùíú*x - y ||_2^2 + Œ£ R_i(x), where || ùíú*x - y ||_2^2 is the consistency term, R_i are the regularization terms, ùíú is the encoding operator, and y is the k-space data.\n\nWhen normalop optimization is disabled, the reported value of f(x) is exactly the consistency term\n\n|| ùíú*x - y ||_2^2. When enabled, it exploits the fact that ‚àáf(x) = ùíú'*(ùíú*x - y) = ùíú'*ùíú*x - ùíú'*y, and usually there exists an optimized operator for ùíú'*ùíú. Therefore, it computes f(x) as || ùíú'*ùíú*x - ùíú'*y ||_2^2, which leads to the same result, but with potentially improved efficiency.\n\nProblem Decomposition\n\nIf disable_problem_decomposition is false, the function automatically decomposes the reconstruction problem\n\nover batch dimensions of the image that are not affected by the Fourier transform or regularization terms.\n\nE.g., for a 3D+t acquisition with no regularization, the reconstruction is decomposed over the time dimension,\n\nand each 3D volume is reconstructed independently.\n\nThis can significantly speed up the reconstruction when multiple CPU cores are available. Usually, this leads\n\nto better resource utilization and faster overall reconstruction times, but is useful to disable for debug purposes.\n\n\n\n\n\n","category":"function"},{"location":"high-level/reconstruction/#MriReconstructionToolbox.Config","page":"Reconstruction","title":"MriReconstructionToolbox.Config","text":"Config(; kwargs...)\n\nGlobal reconstruction configuration used by reconstruct and internal routines. It centralizes iteration control, tolerances, normalization, threading, and automatic problem decomposition behavior.\n\nFields (with defaults):\n\nnormalization::Normalization = BartScaling() ‚Äî scaling applied to operators/data\ntol::Float64 = 1e-4 ‚Äî stopping tolerance for iterative algorithms\nmaxit::Int = 100 ‚Äî maximum iterations for the chosen solver\nfreq::Union{Nothing,Int} = nothing ‚Äî progress print frequency (iterations)\nverbose::Bool = true ‚Äî enable/disable logging output\nthreaded::Bool = (Threads.nthreads() > 1) ‚Äî enable threaded execution when available\nexact_opnorm::Bool = false ‚Äî use exact operator norm for stepsize estimation\ndecomposition_executor::Union{Nothing,ReconstructionExecutor} = nothing ‚Äî override executor for decomposition\ndisableinversescale_output::Bool = false ‚Äî skip rescaling the final output\ndisablenormalopoptimization::Bool = false ‚Äî disable normal-operator optimizations\ndisableproblemdecomposition::Bool = false ‚Äî disable automatic problem decomposition\ndisableoperatornormalization::Bool = false ‚Äî disable operator normalization\nprintfunc::Function = println ‚Äî custom logging function\n\nConstructors:\n\nConfig(; kwargs...) ‚Äî build from defaults, override selected fields\nConfig(config::Config; kwargs...) ‚Äî extend an existing config overriding selected fields\n\nExamples\n\nusing MriReconstructionToolbox\n\n# Default config\nconf = Config()\n\n# Custom tolerances and iterations\nconf = Config(; tol=1e-5, maxit=200, verbose=false)\n\n# Extend an existing config\nconf2 = Config(conf; maxit=50, disable_problem_decomposition=true)\n\n# Use with reconstruct (keywords still override config fields)\nxÃÇ = reconstruct(acq; config=conf2, maxit=25)\n\n\n\n\n\n","category":"type"},{"location":"high-level/reconstruction/#MriReconstructionToolbox.NoScaling","page":"Reconstruction","title":"MriReconstructionToolbox.NoScaling","text":"NoScaling() <: Normalization\n\nA normalization strategy that applies no scaling to the data.\n\n\n\n\n\n","category":"type"},{"location":"high-level/reconstruction/#MriReconstructionToolbox.BartScaling","page":"Reconstruction","title":"MriReconstructionToolbox.BartScaling","text":"BartScaling() <: Normalization\n\nA normalization strategy that mimics the scaling used in BART. This approach inspects the distribution of the absolute values of the initial guess x‚ÇÄ (obtained as the adjoint of the encoding operator applied to the measured k-space data) and selects either the 90th percentile or the maximum value, depending on the spread of the values. If the difference between the maximum and the 90th percentile is less than twice the difference between the 90th percentile and the median, the 90th percentile is used; otherwise, the maximum value is used. This helps to avoid scaling based on outliers in the data.\n\n\n\n\n\n","category":"type"},{"location":"high-level/reconstruction/#MriReconstructionToolbox.MeasurementBasedScaling","page":"Reconstruction","title":"MriReconstructionToolbox.MeasurementBasedScaling","text":"MeasurementBasedScaling() <: Normalization\n\nA normalization strategy that scales the data based on the average absolute value of the k-space measurements. This approach mimic the normalization of MeasurementBasedNormalization from RegularizedLeastSquares.jl (which is used by MRIReco.jl).\n\n\n\n\n\n","category":"type"},{"location":"theory/#Theoretical-Background","page":"Theoretical Background","title":"Theoretical Background","text":"","category":"section"},{"location":"theory/#MRI-Forward-Model","page":"Theoretical Background","title":"MRI Forward Model","text":"The MRI forward model describes how an image transforms into observed k-space data:\n\ny = Gamma mathcalF mathcalS x + n\n\nWhere:\n\nx in mathbbC^N_x times N_y times N_z is the image to be reconstructed\nmathcalS represents coil sensitivity weighting operator\nmathcalF is the Fourier transform operator\nGamma is the subsampling operator\ny is the observed k-space data\nn is measurement noise\n\nThese operators are all linear maps, and they are usually represented as complex matrices in the literature. Even though, in practice, we implement them as efficient computational operators without explicitly forming large matrices, it gives theoretical background for defining adjoint operations (complex conjugate of transpose for matrices) that are essential for iterative reconstruction algorithms.","category":"section"},{"location":"theory/#Operator-Components","page":"Theoretical Background","title":"Operator Components","text":"","category":"section"},{"location":"theory/#1.-Sensitivity-Map-Operator-(S)","page":"Theoretical Background","title":"1. Sensitivity Map Operator (S)","text":"Models the spatial sensitivity of receiver coils in parallel imaging:\n\nS mathbbC^N_x times N_y times N_z rightarrow mathbbC^N_x times N_y times N_z times N_c\n\nForward operation: (Sx)_c = s_c odot x (element-wise multiplication)\n\nAdjoint operation: S^H y = sum_c=1^N_c bars_c odot y_c (coil combination)\n\nWhere s_c is the sensitivity map for coil c, odot denotes element-wise multiplication, N_c is the number of coils, and bars_c is the complex conjugate of s_c.","category":"section"},{"location":"theory/#2.-Fourier-Transform-Operator-(‚Ñ±)","page":"Theoretical Background","title":"2. Fourier Transform Operator (‚Ñ±)","text":"Transforms between image and k-space:\n\nmathcalF mathbbC^N_x times N_y times N_z rightarrow mathbbC^N_x times N_y times N_z\n\nForward operation: Discrete Fourier Transform (DFT) Adjoint operation: Inverse DFT (scaled appropriately)","category":"section"},{"location":"theory/#3.-Subsampling-Operator-(Œì)","page":"Theoretical Background","title":"3. Subsampling Operator (Œì)","text":"Selects observed k-space locations according to an undersampling pattern:\n\nGamma mathbbC^N_x times N_y times N_z rightarrow mathbbC^Omega\n\nWhere Omega is the set of sampled k-space locations.","category":"section"},{"location":"theory/#Reconstruction-as-Inverse-Problem","page":"Theoretical Background","title":"Reconstruction as Inverse Problem","text":"The most simple way of reconstructing the image x from observed data y is to apply the adjoint of the encoding operator:\n\nE^H y = mathcalS^H mathcalF^H Gamma^H y\n\nFor fully sampled data without noise, this gives the least-squares solution. However, in practice, data is often undersampled and noisy, making direct inversion ill-posed. To address this, we formulate the reconstruction as a regularized inverse problem, formulated as:\n\nhatx = argmin_x frac12Ex - y_2^2 + lambda R(x)\n\nWhere:\n\nfrac12Ex - y_2^2 is the data fidelity term\nR(x) is a regularization term (e.g., sparsity, total variation)\nlambda controls the regularization strength\n\nThe encoding operator E makes this optimization problem well-defined and computationally tractable.","category":"section"},{"location":"theory/#Regularization-Techniques","page":"Theoretical Background","title":"Regularization Techniques","text":"The regularization term R(x) can take various forms depending on the desired image properties:\n\nL2 Regularization: R(x) = x_2^2 -> Promotes smoothness\nL1 Wavelet Regularization: R(x) = Psi x_1 where Psi is a wavelet transform -> Promotes sparsity in the wavelet domain\nTotal Variation (TV): R(x) = nabla x_1 -> Preserves edges while reducing noise\n\nThe regularization terms are represented by a (linear) operator and a norm function in general:\n\nR(x) = f(mathcalT x)\n\nwhere mathcalT is some transform operator and f is a norm function (e.g., L1, L2, nuclear norm, etc.).","category":"section"},{"location":"theory/#Optimization-Algorithms","page":"Theoretical Background","title":"Optimization Algorithms","text":"Various iterative algorithms can be employed to solve the regularized inverse problem, most commonly:\n\nGradient Descent (usually conjugate gradient): If R(x) is differentiable\nProximal Gradient Methods: For non-differentiable R(x)\n\nProximal gradient methods alternate between gradient descent on the data fidelity term and applying the proximal operator of the regularization term. The proximal operator is defined as:\n\ntextprox_alpha R(v) = argmin_x frac12x - v_2^2 + alpha R(x)\n\nWhile it is inefficient to solve this minimization directly, many common regularization terms have closed-form proximal operators. For example, the proximal operator for L1 regularization is soft-thresholding:\n\ntextprox_alpha cdot_1(v) = textsign(v) odot max(v - alpha 0)","category":"section"},{"location":"low-level/operators/#MRI-Operators","page":"MRI Operators","title":"MRI Operators","text":"This page documents the low-level operator interface for MRI reconstruction. These operators model the physical MRI encoding process and its components: Fourier transforms, coil sensitivity maps, and k-space subsampling patterns.","category":"section"},{"location":"low-level/operators/#Overview","page":"MRI Operators","title":"Overview","text":"The MRI encoding operator mathcalA maps an image to k-space measurements:\n\ny = mathcalA x = Gamma mathcalF S x\n\nwhere:\n\nS: Sensitivity map operator (coil sensitivities)\n‚Ñ±: Fourier transform operator\nŒì: Subsampling operator (k-space sampling pattern)\nx: Image (single-coil)\ny: Acquired k-space data (multi-coil, potentially undersampled)","category":"section"},{"location":"low-level/operators/#API-Reference","page":"MRI Operators","title":"API Reference","text":"","category":"section"},{"location":"low-level/operators/#Encoding-Operators","page":"MRI Operators","title":"Encoding Operators","text":"The encoding operator is the primary interface for creating complete MRI forward models.","category":"section"},{"location":"low-level/operators/#Usage-Patterns","page":"MRI Operators","title":"Usage Patterns","text":"using MriReconstructionToolbox\n\n# Single-coil, fully sampled\nksp = rand(ComplexF32, 64, 64)\nget_encoding_operator(ksp, false)\n\n# Multi-coil parallel imaging\nksp_mc = rand(ComplexF32, 64, 64, 8)\nsensitivity_maps = coil_sensitivities(64, 64, 8)\nget_encoding_operator(ksp_mc, false; sensitivity_maps=sensitivity_maps)\n\n# Undersampled reconstruction\nmask = rand(Bool, 64, 64)\nmask[28:36, 28:36] .= true  # Fully sample center\nksp_sub = rand(ComplexF32, sum(mask), 8)\n\nget_encoding_operator(\n    ksp_sub, false; \n    sensitivity_maps=sensitivity_maps,\n    image_size=(64, 64), \n    subsampling=mask\n)","category":"section"},{"location":"low-level/operators/#With-Named-Dimensions","page":"MRI Operators","title":"With Named Dimensions","text":"using NamedDims\n\nksp_named = NamedDimsArray{(:kx, :ky, :coil)}(rand(ComplexF32, 64, 64, 8))\nsmaps_named = NamedDimsArray{(:x, :y, :coil)}(coil_sensitivities(64, 64, 8))\n\nget_encoding_operator(ksp_named; sensitivity_maps=smaps_named)","category":"section"},{"location":"low-level/operators/#Keyword-Arguments","page":"MRI Operators","title":"Keyword Arguments","text":"All encoding operator methods support:\n\nsensitivity_maps=nothing: Sensitivity maps for parallel imaging\nimage_size=nothing: Image size (required for subsampled reconstruction)\nsubsampling=nothing: Subsampling pattern\nthreaded::Bool=true: Enable multi-threading\nfast_planning::Bool=false: Use fast FFTW planning","category":"section"},{"location":"low-level/operators/#Fourier-Operators","page":"MRI Operators","title":"Fourier Operators","text":"Fourier operators implement the discrete Fourier transform between image space and k-space.","category":"section"},{"location":"low-level/operators/#Mathematical-Background","page":"MRI Operators","title":"Mathematical Background","text":"Forward transform (image ‚Üí k-space):\n\nk(uv) = sum_x=0^N_x-1 sum_y=0^N_y-1 I(xy) e^-2pi i (uxN_x + vyN_y)\n\nInverse transform (k-space ‚Üí image):\n\nI(xy) = frac1N_x N_y sum_u=0^N_x-1 sum_v=0^N_y-1 k(uv) e^2pi i (uxN_x + vyN_y)","category":"section"},{"location":"low-level/operators/#Basic-Usage","page":"MRI Operators","title":"Basic Usage","text":"# 2D Fourier transform\nimg = rand(ComplexF32, 64, 64)\nF = get_fourier_operator(img, false)  # false = 2D\n\nksp_fft = F * img        # Forward FFT\nimg_recon = F' * ksp_fft # Inverse FFT\nnothing # hide\n\n# 3D Fourier transform\nimg_3d = rand(ComplexF32, 64, 64, 32)\nF_3d = get_fourier_operator(img_3d, true)  # true = 3D\nnothing # hide\n\n# Multi-coil data (FFT applied per coil)\nksp_multi = rand(ComplexF32, 64, 64, 8)\nF_multi = get_fourier_operator(ksp_multi, false)\nimg_multi = F_multi' * ksp_multi  # Shape: (64, 64, 8)\nnothing # hide","category":"section"},{"location":"low-level/operators/#Dimension-Name-Mappings","page":"MRI Operators","title":"Dimension Name Mappings","text":"When using NamedDimsArray, dimension names are automatically mapped:\n\n| Image Space | K-space | |‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì-|‚Äì‚Äì‚Äì‚Äì-|| | :x        | :kx   | | :y        | :ky   | | :z        | :kz   |\n\n# Create k-space data with proper dimension names\nksp_named = NamedDimsArray{(:kx, :ky)}(rand(ComplexF32, 64, 64))\nF_named = get_fourier_operator(ksp_named, false)\n\n# The operator preserves dimension names during inverse FFT\nimg_named = F_named' * ksp_named\nprintln(\"K-space dimensions: \", dimnames(ksp_named))\nprintln(\"Image dimensions: \", dimnames(img_named))","category":"section"},{"location":"low-level/operators/#Implementation-Details","page":"MRI Operators","title":"Implementation Details","text":"FFTW Integration: Uses FFTW.jl for high-performance computation\nFFTW.MEASURE (default): Optimal performance with longer planning\nFFTW.ESTIMATE: Faster planning with potentially slower execution\nMulti-threading: Automatically uses all available threads when threaded=true\nDimension Handling: \n2D: FFT along dimensions (1, 2)\n3D: FFT along dimensions (1, 2, 3)\nBatch dimensions (coils, time) are preserved","category":"section"},{"location":"low-level/operators/#Sensitivity-Map-Operators","page":"MRI Operators","title":"Sensitivity Map Operators","text":"Sensitivity map operators model the spatial sensitivity profiles of receiver coils in parallel MRI.","category":"section"},{"location":"low-level/operators/#Mathematical-Formulation","page":"MRI Operators","title":"Mathematical Formulation","text":"Forward operation (single-coil ‚Üí multi-coil):\n\n(S x)_c = s_c odot x\n\nAdjoint operation (multi-coil ‚Üí single-coil):\n\nS^H y = sum_c=1^N_c bars_c odot y_c\n\nwhere s_c is the sensitivity map for coil c, odot denotes element-wise multiplication, and N_c is the number of coils.","category":"section"},{"location":"low-level/operators/#Basic-Usage-2","page":"MRI Operators","title":"Basic Usage","text":"# 2D multi-coil sensitivity maps\nnx, ny, nc = 64, 64, 8\nsmaps = coil_sensitivities(nx, ny, nc)\nS = get_sensitivity_map_operator(smaps, false)\n\n# Forward: single-coil ‚Üí multi-coil\nimg_single = rand(ComplexF32, nx, ny)\nmulti_coil = S * img_single\nprintln(\"Multi-coil size: \", size(multi_coil))  # (64, 64, 8)\n\n# Adjoint: multi-coil ‚Üí combined image\nimg_combined = S' * multi_coil\nprintln(\"Combined size: \", size(img_combined))  # (64, 64)","category":"section"},{"location":"low-level/operators/#3D-Sensitivity-Maps","page":"MRI Operators","title":"3D Sensitivity Maps","text":"# 3D sensitivity maps\nnx, ny, nz, nc = 64, 64, 32, 8\nsmaps_3d = coil_sensitivities(nx, ny, nz, nc)\nS_3d = get_sensitivity_map_operator(smaps_3d, true)\n\nimg_3d = rand(ComplexF32, nx, ny, nz)\nmulti_coil_3d = S_3d * img_3d\nprintln(\"3D multi-coil size: \", size(multi_coil_3d))  # (64, 64, 32, 8)","category":"section"},{"location":"low-level/operators/#Multi-Slice-with-Per-Slice-Sensitivity-Maps","page":"MRI Operators","title":"Multi-Slice with Per-Slice Sensitivity Maps","text":"# Per-slice sensitivity maps\nnx, ny, nc, nz = 64, 64, 8, 20\nsmaps_per_slice = repeat(coil_sensitivities(nx, ny, nc), outer=(1, 1, 1, nz))\n\nS_multislice = get_sensitivity_map_operator(smaps_per_slice, false)\n\nimg_slices = rand(ComplexF32, nx, ny, nz)\nmulti_coil_slices = S_multislice * img_slices\nprintln(\"Multi-slice coil size: \", size(multi_coil_slices))  # (64, 64, 8, 20)","category":"section"},{"location":"low-level/operators/#Batch-Dimensions-(Dynamic-Imaging)","page":"MRI Operators","title":"Batch Dimensions (Dynamic Imaging)","text":"# Sensitivity maps for dynamic imaging\nnx, ny, nc, nt = 64, 64, 8, 30  # 30 time frames\nsmaps_dyn = coil_sensitivities(nx, ny, nc)\n\nS_dynamic = get_sensitivity_map_operator(\n    smaps_dyn, false; \n    batch_dims=(nt,)\n)\n\nimg_dynamic = rand(ComplexF32, nx, ny, nt)\nmulti_coil_dynamic = S_dynamic * img_dynamic\nprintln(\"Dynamic multi-coil size: \", size(multi_coil_dynamic))  # (64, 64, 8, 30)","category":"section"},{"location":"low-level/operators/#Required-Array-Shapes","page":"MRI Operators","title":"Required Array Shapes","text":"2D Sensitivity Maps:\n\nSingle slice: (nx, ny, ncoils)\nMulti-slice: (nx, ny, ncoils, nslices)\n\n3D Sensitivity Maps:\n\nStandard: (nx, ny, nz, ncoils)\n\nNamedDims Requirements:\n\nMust include :x, :y (and :z for 3D)\nMust have :coil as the last spatial dimension\nDimension order: :x, :y, [:z], :coil","category":"section"},{"location":"low-level/operators/#Physical-Interpretation","page":"MRI Operators","title":"Physical Interpretation","text":"The adjoint operation S^H performs optimal coil combination:\n\nx_textcombined = S^H y = sum_c=1^N_c bars_c odot y_c\n\nThis weighted combination assigns higher weights to regions where each coil has stronger sensitivity, accounting for spatial response and phase variations.","category":"section"},{"location":"low-level/operators/#Subsampling-Operators","page":"MRI Operators","title":"Subsampling Operators","text":"Subsampling operators model undersampled k-space acquisition patterns for accelerated MRI.","category":"section"},{"location":"low-level/operators/#Mathematical-Formulation-2","page":"MRI Operators","title":"Mathematical Formulation","text":"Forward operation (extract sampled locations):\n\ny = Gamma x\n\nAdjoint operation (zero-fill unsampled locations):\n\nGamma^H y = textzero-filled full k-space\n\nThe adjoint places acquired data at sampled locations and zeros elsewhere.","category":"section"},{"location":"low-level/operators/#Subsampling-Pattern-Types","page":"MRI Operators","title":"Subsampling Pattern Types","text":"","category":"section"},{"location":"low-level/operators/#2D-Patterns","page":"MRI Operators","title":"2D Patterns","text":"# Boolean mask\nmask_bool = rand(Bool, 64, 64)\nmask_bool[30:35, 30:35] .= true  # Fully sample center\nprintln(\"Acceleration: \", round(64*64/sum(mask_bool), digits=2), \"x\")\n\n# Linear indices\nindices_linear = [1, 10, 50, 100, 500, 1000]\nnothing # hide\n\n# Cartesian indices\ncart_indices = [CartesianIndex(i, j) for i in 1:64 for j in 1:64 if rand() < 0.3]\nnothing # hide\n\n# Separable pattern (independent per dimension)\npattern_x = 1:2:64        # Every other line\npattern_y = rand(Bool, 64)  # Random sampling\npattern_sep = (pattern_x, pattern_y)\nnothing # hide","category":"section"},{"location":"low-level/operators/#3D-Patterns","page":"MRI Operators","title":"3D Patterns","text":"# 3D boolean mask\nmask_3d = rand(Bool, 64, 64, 32)\nmask_3d[30:35, 30:35, 14:18] .= true\nnothing # hide\n\n# Separable 3D\npattern_3d = (1:64, rand(Bool, 64), 1:2:32)  # (x: all, y: random, z: every other)\nnothing # hide\n\n# Hybrid 2D+1D (common for 3D Cartesian)\nmask_2d = rand(Bool, 64, 64)\npattern_kz = 1:2:32\npattern_hybrid = (mask_2d, pattern_kz)\nnothing # hide","category":"section"},{"location":"low-level/operators/#Basic-Usage-3","page":"MRI Operators","title":"Basic Usage","text":"# Create undersampling pattern\nnx, ny = 64, 64\nmask = rand(Bool, nx, ny)\nmask[30:35, 30:35] .= true\n\n# Subsample k-space (use tuple pattern)\nksp_full = rand(ComplexF32, nx, ny, 8)\nindices = findall(mask)\nksp_sub = ksp_full[indices, :]\n\n# Create subsampling operator with tuple pattern\nŒì = get_subsampling_operator(ksp_sub, (nx, ny), (mask,))\n\n# Zero-fill reconstruction\nksp_zerofilled = Œì' * ksp_sub\nprintln(\"Zero-filled size: \", size(ksp_zerofilled))  # (64, 64, 8)","category":"section"},{"location":"low-level/operators/#Combined-Operations","page":"MRI Operators","title":"Combined Operations","text":"For complete encoding including Fourier and subsampling, use get_encoding_operator:\n\n# Complete encoding operator: Image ‚Üí Subsampled k-space\nimg_size = (64, 64)\nsmaps_enc = coil_sensitivities(64, 64, 8)\nE_complete = get_encoding_operator(\n    ksp_sub, false;\n    sensitivity_maps=smaps_enc,\n    image_size=img_size,\n    subsampling=(mask,)\n)\n\n# Direct operations\nimg = rand(ComplexF32, 64, 64)\nksp_acquired = E_complete * img        # Forward\nimg_recon = E_complete' * ksp_acquired # Adjoint\nnothing # hide","category":"section"},{"location":"low-level/operators/#Multi-Slice-2D-Subsampling","page":"MRI Operators","title":"Multi-Slice 2D Subsampling","text":"# For multi-slice data, the encoding operator handles it automatically\nnx, ny, nz = 64, 64, 20\nmask_2d = rand(Bool, nx, ny)\nindices_2d = findall(mask_2d)\n\n# Each slice uses the same subsampling pattern\nksp_full_ms = rand(ComplexF32, nx, ny, 8, nz)\nksp_sub_ms = similar(ksp_full_ms, sum(mask_2d), 8, nz)\nfor iz in 1:nz\n    ksp_sub_ms[:, :, iz] = ksp_full_ms[indices_2d, :, iz]\nend\n\nprintln(\"Multi-slice subsampled size: \", size(ksp_sub_ms))","category":"section"},{"location":"low-level/operators/#Supported-Pattern-Formats","page":"MRI Operators","title":"Supported Pattern Formats","text":"2D Patterns:\n\nFormat Example Description\nBoolean 2D mask::Array{Bool,2} Arbitrary 2D sampling\nLinear indices indices::Vector{Int} Flattened k-space indices\nCartesian indices indices::Vector{CartesianIndex{2}} 2D coordinates\nSeparable (pattern_x, pattern_y) Independent per dimension\n\n3D Patterns:\n\nFormat Example Description\nBoolean 3D mask::Array{Bool,3} Arbitrary 3D sampling\nSeparable (pattern_x, pattern_y, pattern_z) Independent per dimension\nHybrid 1D+2D (pattern_x, mask_yz) 1D pattern + 2D mask\nHybrid 2D+1D (mask_2d, pattern_z) 2D mask + 1D pattern","category":"section"},{"location":"low-level/operators/#Acceleration-Factor","page":"MRI Operators","title":"Acceleration Factor","text":"The acceleration factor R quantifies undersampling:\n\nmask = rand(Bool, 128, 128)\nfull_samples = 128 * 128\nacquired_samples = sum(mask)\nacceleration = full_samples / acquired_samples\nprintln(\"Acceleration factor: \", round(acceleration, digits=2), \"x\")\n\nTypical ranges:\n\nCartesian 2D: R = 2-6\nCartesian 3D: R = 3-10\nRadial/Spiral: R = 4-12\nRandom: R = 2-8\n\nHigher acceleration requires stronger regularization for good reconstruction quality.","category":"section"},{"location":"low-level/operators/#Integration-with-AcquisitionInfo","page":"MRI Operators","title":"Integration with AcquisitionInfo","text":"Extract operators directly from AcquisitionInfo:\n\n# Create acquisition info\nmask_acq = rand(Bool, 64, 64)\nindices_acq = findall(mask_acq)\nksp_sub_acq = rand(ComplexF32, sum(mask_acq), 8)\nsmaps_acq = coil_sensitivities(64, 64, 8)\n\nacq_info = AcquisitionInfo(\n    ksp_sub_acq; \n    is3D=false,\n    image_size=(64, 64),\n    subsampling=(mask_acq,),\n    sensitivity_maps=smaps_acq\n)\n\n# Extract operators\nE = get_encoding_operator(acq_info)\nS = get_sensitivity_map_operator(acq_info)\nŒì = get_subsampling_operator(acq_info)\n\nprintln(\"Encoding operator type: \", typeof(E))","category":"section"},{"location":"low-level/operators/#See-Also","page":"MRI Operators","title":"See Also","text":"AcquisitionInfo - High-level configuration\nReconstruction - Using operators in reconstruction\nSimulation Tools - Generate test data and patterns","category":"section"},{"location":"low-level/operators/#MriReconstructionToolbox.get_encoding_operator","page":"MRI Operators","title":"MriReconstructionToolbox.get_encoding_operator","text":"get_encoding_operator(info::AcquisitionInfo; threaded::Bool=true, fast_planning::Bool=false)\nget_encoding_operator(ksp, is3D::Bool; sensitivity_maps=nothing, image_size=nothing, subsampling=nothing, threaded=true, fast_planning=false)\nget_encoding_operator(ksp::NamedDimsArray; sensitivity_maps=nothing, image_size=nothing, subsampling=nothing, threaded=true, fast_planning=false)\n\nCreate the main MRI encoding operator for data acquisition modeling.\n\nArguments for AcquisitionInfo method\n\ninfo::AcquisitionInfo: Contains k-space data, sensitivity maps, image size, subsampling pattern, and other acquisition parameters.\n\nArguments for raw k-space method\n\nksp: K-space data array\nis3D::Bool: Whether the acquisition is 3D\nsensitivity_maps: Coil sensitivity maps (optional)\nimage_size: Image size tuple (optional)\nsubsampling: Subsampling pattern (optional)\n\nArguments for NamedDimsArray method\n\nksp::NamedDimsArray: K-space data with named dimensions\nsensitivity_maps: Coil sensitivity maps (optional, can be NamedDimsArray)\nimage_size: Image size tuple (optional, Tuple{Int,Int} or Tuple{Int,Int,Int})\nsubsampling: Subsampling pattern (optional, 2D or 3D pattern)\n\nCommon keyword arguments\n\nthreaded::Bool=true: Whether to use multi-threading for operator construction and FFTs.\nfast_planning::Bool=false: Whether to use fast FFTW planning (reduces setup time, may affect performance).\n\nReturns\n\nEncoding operator modeling the full MRI acquisition process, including Fourier transform, sensitivity map encoding, and subsampling (if present).\n\nDetails\n\nThis function constructs the composite encoding operator E that models the MRI data acquisition pipeline:\n\nApplies sensitivity map encoding (if provided)\nApplies Fourier transform (subsampled if a subsampling pattern is present)\nReturns the composed operator E = F * S or E = F\n\nIf no sensitivity maps are provided, only the Fourier/subsampled Fourier operator is returned.\n\n\n\n\n\n","category":"function"},{"location":"low-level/operators/#MriReconstructionToolbox.get_fourier_operator","page":"MRI Operators","title":"MriReconstructionToolbox.get_fourier_operator","text":"get_fourier_operator(ksp, [is3D], [shifted_kspace_dims], [shifted_image_dims]; threaded=true, fast_planning=false)\nget_fourier_operator(info::AcquisitionInfo; threaded=true, fast_planning=false)\n\nCreate a Fourier transform operator for MRI data.\n\nThe operator transforms between image space and k-space using the discrete Fourier transform. For named dimension arrays, automatically detects 2D vs 3D from dimension names. For regular arrays, specify is3D explicitly.\n\nArguments with explicit types\n\nksp: K-space data array (NamedDimsArray or AbstractArray)\nis3D::Bool: Whether the data is 3D (required for AbstractArray; optionally auto-detected for NamedDimsArray)\nshifted_kspace_dims::Tuple: Dimensions in k-space where the DC is at the first index instead of the center (useful for pre-shifted data, default: empty)\nshifted_image_dims::Tuple: Dimensions in image space requiring fftshift (equivalent to an kspace-domain sign-alternation, default: empty)\nthreaded::Bool: Whether to use multi-threading for FFT operations (default: true)\nfast_planning::Bool: If true, use FFTW.ESTIMATE for faster planning (default: false)\n\nReturns\n\nFourier transform operator\n\nMethod Variants\n\nNamedDimsArray: Automatically determines 2D vs 3D from the presence of :kz dimension\nAbstractArray: Requires explicit is3D parameter to determine dimensionality\nAcquisitionInfo: Extracts ksp, is3D, shifted_kspace_dims, and shifted_image_dims from the AcquisitionInfo struct\n\n\n\n\n\n","category":"function"},{"location":"low-level/operators/#MriReconstructionToolbox.get_sensitivity_map_operator","page":"MRI Operators","title":"MriReconstructionToolbox.get_sensitivity_map_operator","text":"get_sensitivity_map_operator(sensitivity_maps, [is3D]; batch_dims=nothing, threaded=true)\n\nCreate a sensitivity map operator for parallel MRI reconstruction.\n\nArguments\n\nsensitivity_maps: Sensitivity maps for each coil (NamedDimsArray or AbstractArray)\nis3D::Bool: Whether the sensitivity maps are 3D (required for AbstractArray; auto-detected for NamedDimsArray)\nbatch_dims: Batch dimensions specification (NamedTuple for NamedDimsArray, Tuple for AbstractArray, optional)\nthreaded::Bool=true: Whether to use multi-threading for operations\n\nReturns\n\nSensitivity map operator (NamedDimsOp for NamedDimsArray inputs, Compose for AbstractArray inputs)\n\nMethod Variants\n\nNamedDimsArray: Automatically detects 2D vs 3D from dimension names, uses NamedTuple for batch_dims\nAbstractArray: Requires explicit is3D parameter, uses Tuple for batch_dims\n\nRequired dimension names (NamedDimsArray method)\n\n:x: First spatial dimension (required, must be first dimension)\n:y: Second spatial dimension (required, must be second dimension)\n:z: Third spatial dimension (optional, must be third dimension if present)\n:coil: Coil dimension (required, must be last dimension)\n\nArray shapes (AbstractArray method)\n\n2D: (nx, ny, ncoils) or (nx, ny, ncoils, batch_dims...)\n3D: (nx, ny, nz, ncoils) or (nx, ny, nz, ncoils, batch_dims...)\n\nDetails\n\nThe operator multiplies single-coil images by the sensitivity maps to produce multi-coil images. The adjoint operation combines multi-coil images using the conjugate of the sensitivity maps.\n\nForward operation: multi_coil_images = S * single_coil_image Adjoint operation: combined_image = S' * multi_coil_images\n\nThe operator is constructed as:\n\nDiagOp(sensitivity_maps): Element-wise multiplication with sensitivity maps\nBroadCast(Eye(dummy_img), size(sensitivity_maps)): Broadcasting identity for image dimensions\nBatchOp(...): If batch dimensions are present, wrap in batch operator\n\n\n\n\n\n","category":"function"},{"location":"low-level/operators/#MriReconstructionToolbox.get_subsampling_operator","page":"MRI Operators","title":"MriReconstructionToolbox.get_subsampling_operator","text":"get_subsampling_operator(subsampled_ksp, img_size, subsampling)\nget_subsampling_operator(info::AcquisitionInfo)\n\nCreate the subsampling operator Œì that maps full k-space to a given subsampled layout. This is useful when you need Œì separately or want to compose it with other operators manually. For a combined Œì * ‚Ñ± operator, use get_subsampled_fourier_operator.\n\nArguments\n\nsubsampled_ksp: Subsampled k-space array (Array or NamedDimsArray). Used to determine batch dimensions and, for named arrays, validate dimension names.\nimg_size: Full image size as (nx, ny) or (nx, ny, nz).\nsubsampling: Subsampling pattern that produced subsampled_ksp. Supports boolean masks and tuples mixing Colon, boolean masks, and ranges.\ninfo::AcquisitionInfo: Alternative API that takes configuration from a validated AcquisitionInfo (must contain image_size and subsampling).\n\nReturns\n\nŒì: A GetIndex or BatchOp{GetIndex}. For NamedDims inputs, a NamedDimsOp wrapping the un-named Œì is returned to preserve dimension names.\n\nDetails\n\nFor NamedDims input, validates that dimnames(subsampled_ksp) matches the names implied by the subsampling pattern and the full k-space layout.\nBatch dimensions (beyond the spatial dims) are preserved; Œì becomes a batch operator when needed.\n\nExamples\n\nusing MriReconstructionToolbox\n\n# 2D mask, array input\nksp_full = rand(ComplexF32, 64, 64, 8)\nmask = rand(Bool, 64, 64)\nksp_sub = ksp_full[mask, :]\nŒì = get_subsampling_operator(ksp_sub, (64, 64), mask)\n\n# 2D NamedDims input\nusing NamedDims\nksp_nd = NamedDimsArray{(:kxy, :coil)}(ksp_sub)\nŒì_nd = get_subsampling_operator(ksp_nd, (64, 64), mask)\n\n# Via AcquisitionInfo\ninfo = AcquisitionInfo(ksp_sub; is3D=false, image_size=(64, 64), subsampling=mask)\nŒì_info = get_subsampling_operator(info)\n\n\n\n\n\n","category":"function"},{"location":"high-level/acquisition_info/#AcquisitionInfo","page":"AcquisitionInfo","title":"AcquisitionInfo","text":"AcquisitionInfo is a validated configuration container for MRI acquisition parameters. It centralizes k-space data, sensitivity maps, image dimensions, subsampling patterns, and FFT shift conventions, performing comprehensive validation at construction time to catch configuration errors early.\n\nBenefits:\n\nCentralized validation: Checks dimension compatibility at construction time\nClear parameter organization: Named fields instead of positional arguments\nType safety: Supports both plain arrays and NamedDimsArray\nReusability: Pass the same config to multiple functions","category":"section"},{"location":"high-level/acquisition_info/#Constructor","page":"AcquisitionInfo","title":"Constructor","text":"","category":"section"},{"location":"high-level/acquisition_info/#Accepted-Input-Types","page":"AcquisitionInfo","title":"Accepted Input Types","text":"","category":"section"},{"location":"high-level/acquisition_info/#K-space-Data","page":"AcquisitionInfo","title":"K-space Data","text":"The first argument can be:\n\nPlain AbstractArray: Standard Julia arrays containing k-space data\nNamedDimsArray: Arrays with named dimensions for automatic inference\nnothing: When setting up acquisition parameters without actual data (e.g., for simulation)","category":"section"},{"location":"high-level/acquisition_info/#Constraints-on-Dimensions","page":"AcquisitionInfo","title":"Constraints on Dimensions","text":"The first two dimensions correspond to transformed spatial axes (kx, ky)\nIt must be followed by transformed z-axis if 3D encoding is used (kz)\nThe next dimension must correspond to coils, if sensitivity maps are provided\nIf 2D encoding is used and sensitivity maps are provided, then slice dimensions must be after the coil dimension\nSensitivity maps must match spatial dimensions of the image:\n2D encoding: (N_x N_y N_c N_z)\n3D encoding: (N_x N_y N_z N_c)\n\nusing MriReconstructionToolbox\n\n# Plain array - requires explicit is3D\nksp_plain = rand(ComplexF32, 64, 64, 8)\nAcquisitionInfo(ksp_plain; is3D=false)\n\nusing NamedDims\n\n# NamedDimsArray - is3D inferred from :kz presence\nksp_named = NamedDimsArray{(:kx, :ky, :coil)}(\n    rand(ComplexF32, 64, 64, 8)\n)\nAcquisitionInfo(ksp_named)  # is3D = false (no :kz)\n\n# 3D with named dimensions\nksp_3d = NamedDimsArray{(:kx, :ky, :kz, :coil)}(\n    rand(ComplexF32, 32, 32, 16, 4)\n)\nAcquisitionInfo(ksp_3d)  # is3D = true (has :kz)\n\n# Without k-space data (for simulation setup)\ninfo4 = AcquisitionInfo(\n    nothing;\n    is3D=false,\n    image_size=(128, 128)\n)","category":"section"},{"location":"high-level/acquisition_info/#Sensitivity-Maps","page":"AcquisitionInfo","title":"Sensitivity Maps","text":"Sensitivity maps must match k-space dimensions and element type:\n\n# 2D single-coil sensitivity maps\nksp = rand(ComplexF32, 64, 64, 8)\nsmaps = rand(ComplexF32, 64, 64, 8)  # (nx, ny, ncoils)\n\nAcquisitionInfo(ksp; is3D=false, sensitivity_maps=smaps)\n\n# 3D sensitivity maps\nksp_3d = rand(ComplexF32, 32, 32, 16, 4)\nsmaps_3d = rand(ComplexF32, 32, 32, 16, 4)  # (nx, ny, nz, ncoils)\n\nAcquisitionInfo(ksp_3d; is3D=true, sensitivity_maps=smaps_3d)\n\n# 2D multi-slice with per-slice sensitivity maps\nksp_ms = rand(ComplexF32, 64, 64, 4, 10)  # 4 coils, 10 slices\nsmaps_ms = rand(ComplexF32, 64, 64, 4, 10)  # (nx, ny, ncoils, nslices)\n\nAcquisitionInfo(ksp_ms; is3D=false, sensitivity_maps=smaps_ms)","category":"section"},{"location":"high-level/acquisition_info/#Subsampling-Patterns","page":"AcquisitionInfo","title":"Subsampling Patterns","text":"Multiple subsampling formats are supported:\n\n# Boolean mask\nmask = rand(Bool, 64, 64)\nmask[25:40, 25:40] .= true  # Fully sample center\n\ninfo_mask = AcquisitionInfo(\n    nothing;\n    is3D=false,\n    image_size=(64, 64),\n    subsampling=mask\n)\n\n# Tuple of Colon and mask for Cartesian undersampling\nmask_ky = rand(Bool, 64)\nmask_ky[28:36] .= true  # Fully sample center lines\n\nAcquisitionInfo(\n    nothing;\n    is3D=false,\n    image_size=(64, 64),\n    subsampling=(:, mask_ky)  # Fully sample kx, undersample ky\n)\n\n# 3D subsampling with multiple dimensions\nmask_3d = rand(Bool, 32, 32, 16)\nmask_3d[13:20, 13:20, 5:12] .= true\n\nAcquisitionInfo(\n    nothing;\n    is3D=true,\n    image_size=(32, 32, 16),\n    subsampling=mask_3d\n)","category":"section"},{"location":"high-level/acquisition_info/#FFT-Shift-Conventions","page":"AcquisitionInfo","title":"FFT Shift Conventions","text":"The provided k-space data is assumed to follow standard FFT conventions (DC at center). Sometimes, data may be pre-shifted (DC at first index) or require image-space shifts. Use shifted_kspace_dims and shifted_image_dims to specify these dimensions:\n\n# Pre-shifted k-space (DC at first index)\nksp = rand(ComplexF32, 64, 64)\n\ninfo_shifted = AcquisitionInfo(\n    ksp;\n    is3D=false,\n    shifted_kspace_dims=(1, 2)  # Both dimensions pre-shifted\n)\n\n# Image-space shifts (equivalent to sign alternation in k-space)\ninfo_img_shift = AcquisitionInfo(\n    ksp;\n    is3D=false,\n    shifted_image_dims=(1,)  # First dimension needs shift\n)\n\n# Named dimensions for shifts\nksp_named = NamedDimsArray{(:kx, :ky)}(rand(ComplexF32, 64, 64))\n\ninfo_named_shift = AcquisitionInfo(\n    ksp_named;\n    shifted_kspace_dims=(:kx, :ky)\n)","category":"section"},{"location":"high-level/acquisition_info/#Validation-Rules","page":"AcquisitionInfo","title":"Validation Rules","text":"AcquisitionInfo performs comprehensive validation to ensure configuration consistency.","category":"section"},{"location":"high-level/acquisition_info/#Dimension-Name-Validation","page":"AcquisitionInfo","title":"Dimension Name Validation","text":"K-space NamedDimsArray must have specific dimension names:\n\ntry\n    # ‚ùå Wrong: using image dimension names\n    bad_ksp = NamedDimsArray{(:x, :y, :coil)}(\n        rand(ComplexF32, 64, 64, 8)\n    )\n    AcquisitionInfo(bad_ksp)\ncatch e\n    println(\"Error: \", e.msg)\nend\n\n# ‚úì Correct: proper k-space dimension names\ngood_ksp = NamedDimsArray{(:kx, :ky, :coil)}(\n    rand(ComplexF32, 64, 64, 8)\n)\ninfo = AcquisitionInfo(good_ksp)\nprintln(\"Success! Dimensions: \", dimnames(info.kspace_data))","category":"section"},{"location":"high-level/acquisition_info/#Dimension-Order-Validation","page":"AcquisitionInfo","title":"Dimension Order Validation","text":"Dimensions must be in the correct order:\n\ntry\n    # ‚ùå Wrong: kx and ky swapped\n    bad_order = NamedDimsArray{(:ky, :kx, :coil)}(\n        rand(ComplexF32, 64, 64, 8)\n    )\n    AcquisitionInfo(bad_order)\ncatch e\n    println(\"Error: \", e.msg)\nend\n\n# ‚úì Correct: kx first, then ky\ngood_order = NamedDimsArray{(:kx, :ky, :coil)}(\n    rand(ComplexF32, 64, 64, 8)\n)\ninfo = AcquisitionInfo(good_order)\nprintln(\"Success!\")","category":"section"},{"location":"high-level/acquisition_info/#Size-Compatibility-Validation","page":"AcquisitionInfo","title":"Size Compatibility Validation","text":"Sensitivity maps must match k-space spatial dimensions:\n\ntry\n    # ‚ùå Wrong: size mismatch\n    ksp_wrong = rand(ComplexF32, 64, 64, 8)\n    smaps_wrong = rand(ComplexF32, 128, 128, 8)  # Different size!\n    AcquisitionInfo(ksp_wrong; is3D=false, sensitivity_maps=smaps_wrong)\ncatch e\n    println(\"Error: \", e.msg)\nend\n\n# ‚úì Correct: matching sizes\nksp = rand(ComplexF32, 64, 64, 8)\nsmaps = rand(ComplexF32, 64, 64, 8)\ninfo = AcquisitionInfo(ksp; is3D=false, sensitivity_maps=smaps)\nprintln(\"Success! K-space: \", size(ksp)[1:2], \", Smaps: \", size(smaps)[1:2])","category":"section"},{"location":"high-level/acquisition_info/#Element-Type-Consistency","page":"AcquisitionInfo","title":"Element Type Consistency","text":"K-space and sensitivity maps must have matching element types:\n\ntry\n    # ‚ùå Wrong: different precision\n    ksp_f32 = rand(ComplexF32, 64, 64, 8)\n    smaps_f64 = rand(ComplexF64, 64, 64, 8)  # Different type!\n    AcquisitionInfo(ksp_f32; is3D=false, sensitivity_maps=smaps_f64)\ncatch e\n    println(\"Error: \", e.msg)\nend\n\n# ‚úì Correct: same element type\nksp = rand(ComplexF32, 64, 64, 8)\nsmaps = rand(ComplexF32, 64, 64, 8)\ninfo = AcquisitionInfo(ksp; is3D=false, sensitivity_maps=smaps)\nprintln(\"Success! Both are \", eltype(ksp))","category":"section"},{"location":"high-level/acquisition_info/#Coil-Dimension-Requirements","page":"AcquisitionInfo","title":"Coil Dimension Requirements","text":"When using NamedDimsArray with sensitivity maps, :coil dimension is required:\n\ntry\n    # ‚ùå Wrong: missing :coil dimension\n    ksp_no_coil = NamedDimsArray{(:kx, :ky)}(\n        rand(ComplexF32, 64, 64)\n    )\n    smaps_wrong = NamedDimsArray{(:x, :y, :coil)}(\n        rand(ComplexF32, 64, 64, 4)\n    )\n    AcquisitionInfo(ksp_no_coil; sensitivity_maps=smaps_wrong)\ncatch e\n    println(\"Error: \", e.msg)\nend\n\n# ‚úì Correct: :coil dimension present\nksp_with_coil = NamedDimsArray{(:kx, :ky, :coil)}(\n    rand(ComplexF32, 64, 64, 4)\n)\nsmaps = NamedDimsArray{(:x, :y, :coil)}(\n    rand(ComplexF32, 64, 64, 4)\n)\ninfo = AcquisitionInfo(ksp_with_coil; sensitivity_maps=smaps)\nprintln(\"Success! Coil dimension: \", size(info.kspace_data, 3), \" coils\")","category":"section"},{"location":"high-level/acquisition_info/#Image-Size-Inference-and-Validation","page":"AcquisitionInfo","title":"Image Size Inference and Validation","text":"image_size is inferred when possible, but can be explicitly provided:\n\n# Inferred from fully sampled k-space\nksp = rand(ComplexF32, 64, 64)\ninfo = AcquisitionInfo(ksp; is3D=false)\nprintln(\"Inferred image size: \", info.image_size)\n\n# Required when subsampling without k-space data\nmask = rand(Bool, 128, 128)\ninfo = AcquisitionInfo(\n    nothing;\n    is3D=false,\n    image_size=(128, 128),\n    subsampling=mask\n)\nprintln(\"Explicit image size: \", info.image_size)\n\ntry\n    # ‚ùå Wrong: missing image_size with subsampling\n    mask_wrong = rand(Bool, 64, 64)\n    AcquisitionInfo(\n        nothing;\n        is3D=false,\n        subsampling=mask_wrong\n        # Missing image_size!\n    )\ncatch e\n    println(\"Error: \", e.msg)\nend","category":"section"},{"location":"high-level/acquisition_info/#3D-vs-2D-Validation","page":"AcquisitionInfo","title":"3D vs 2D Validation","text":"Correct dimensionality must be specified or inferred:\n\n# 3D requires :kz dimension or explicit is3D=true\nksp_3d = NamedDimsArray{(:kx, :ky, :kz, :coil)}(\n    rand(ComplexF32, 32, 32, 16, 4)\n)\nAcquisitionInfo(ksp_3d)  # Automatically infers is3D=true\n\n# 2D must NOT have :kz dimension\nksp_2d = NamedDimsArray{(:kx, :ky, :coil)}(\n    rand(ComplexF32, 64, 64, 8)\n)\nAcquisitionInfo(ksp_2d)  # Automatically infers is3D=false","category":"section"},{"location":"high-level/acquisition_info/#Updating-Existing-Configurations","page":"AcquisitionInfo","title":"Updating Existing Configurations","text":"You can create new configurations based on existing ones:\n\n# Start with basic config\nksp = rand(ComplexF32, 64, 64, 8)\ninfo1 = AcquisitionInfo(ksp; is3D=false)\nprintln(\"Initial config: \", info1)\n\n# Add sensitivity maps\nsmaps = rand(ComplexF32, 64, 64, 8)\ninfo2 = AcquisitionInfo(info1; sensitivity_maps=smaps)\nprintln(\"With sensitivity maps:\", info2)","category":"section"},{"location":"high-level/acquisition_info/#Integration-with-Other-Functions","page":"AcquisitionInfo","title":"Integration with Other Functions","text":"AcquisitionInfo is accepted by:\n\nReconstruction: reconstruct(acq_info, ...)\nOperators: get_encoding_operator(acq_info), get_fourier_operator(acq_info), etc.\nSimulation: simulate_acquisition(image, acq_info)\n\nThis unified interface simplifies complex workflows and reduces parameter passing errors.","category":"section"},{"location":"high-level/acquisition_info/#MriReconstructionToolbox.AcquisitionInfo","page":"AcquisitionInfo","title":"MriReconstructionToolbox.AcquisitionInfo","text":"AcquisitionInfo(\n        kspace_data;\n        is3D::Union{Bool,Nothing}=nothing,\n        sensitivity_maps=nothing,\n        image_size=nothing,\n        subsampling=nothing,\n        shifted_kspace_dims::Tuple=(),\n        shifted_image_dims::Tuple=(),\n)\n\nConfiguration container for MRI acquisition and encoding settings.\n\nUse this to centralize validation and pass a single object to get_encoding_operator(::AcquisitionInfo) and related helpers. The constructor performs consistency checks across k-space layout, coil maps, subsampling, and image size, and stores threading and FFTW planning preferences.\n\nFields\n\nkspace_data::K: K‚Äëspace data array or template. Can be a plain   AbstractArray or a NamedDimsArray whose first dimensions must   be :kx, :ky (and :kz for 3D). When sensitivity maps are   provided and kspace_data is named, a :coil dimension is required.\nis3D::Bool: Whether data is 3D. If kspace_data is a   NamedDimsArray, this is inferred from the presence of :kz, or   the length of image_size if provided. Otherwise it must be provided.\nsensitivity_maps::S: Coil sensitivity maps or nothing.   Must be 3D (2D + coil) or 4D (3D + coil); element type must match   kspace_data.\nimage_size::I: (nx, ny) for 2D or (nx, ny, nz) for 3D, or   nothing. Required when subsampling is provided and cannot be   inferred from the pattern.\nsubsampling::Sub: Subsampling pattern (2D/3D). Supports boolean   masks and tuples combining Colon, boolean masks, and ranges.\nshifted_kspace_dims::SD: Dimensions in k‚Äëspace where the DC is at the   first index (useful for pre‚Äëshifted data).\nshifted_image_dims::ID: Image dimensions requiring fft shift   (equivalent to an kspace-domain sign-alternation).\n\nWhen kspace_data is a NamedDimsArray, is3D is inferred from the presence of :kz. Otherwise, is3D must be provided. If a subsampling pattern is provided, image_size is validated or inferred when possible.\n\n\n\n\n\n","category":"type"},{"location":"high-level/decomposition/#Problem-Decomposition","page":"Problem Decomposition","title":"Problem Decomposition","text":"Problem decomposition is an advanced feature that automatically parallelizes reconstruction across independent data dimensions, significantly speeding up processing when you have multiple CPU cores.","category":"section"},{"location":"high-level/decomposition/#What-is-Problem-Decomposition?","page":"Problem Decomposition","title":"What is Problem Decomposition?","text":"When you have batch dimensions in your data (like multiple slices, time points, or contrasts), and these dimensions don't interact through the Fourier transform or regularization, the reconstruction problem can be decomposed into independent sub-problems that can be solved in parallel.","category":"section"},{"location":"high-level/decomposition/#Simple-Example","page":"Problem Decomposition","title":"Simple Example","text":"Imagine you have 20 slices to reconstruct:\n\nWithout decomposition:\n\nReconstruct all 20 slices as one large problem\nUses 1 CPU core\nTakes 20 time units\n\nWith decomposition:\n\nAutomatically splits into 20 independent problems\nEach reconstructed on a separate core\nWith 8 cores: takes ~2.5 time units\n**~8√ó speedup!***\n\n*Actual speedup is expected to be lower because even without decomposition, some operations (like FFTs) are multi-threaded.","category":"section"},{"location":"high-level/decomposition/#When-Does-Decomposition-Happen?","page":"Problem Decomposition","title":"When Does Decomposition Happen?","text":"The reconstruct function automatically determines if decomposition is beneficial:\n\n# This will automatically use decomposition if:\n# 1. There are batch dimensions (e.g., time, slice)\n# 2. The batch dimensions aren't affected by regularization\n# 3. decomposition is not disabled\nimg = reconstruct(acq, regularization)","category":"section"},{"location":"high-level/decomposition/#Conditions-for-Decomposition","page":"Problem Decomposition","title":"Conditions for Decomposition","text":"‚úÖ Decomposition is used when:\n\nData has batch dimensions beyond spatial dimensions and coils\nRegularization doesn't couple the batch dimensions\nYou haven't disabled it with disable_problem_decomposition=true\n\n‚ùå Decomposition is NOT used when:\n\nNo batch dimensions exist\nRegularization couples batch dimensions (e.g., temporal regularization)\nExplicitly disabled\nNo regularization specified (direct reconstruction doesn't benefit)","category":"section"},{"location":"high-level/decomposition/#Understanding-Batch-Dimensions","page":"Problem Decomposition","title":"Understanding Batch Dimensions","text":"","category":"section"},{"location":"high-level/decomposition/#What-are-Batch-Dimensions?","page":"Problem Decomposition","title":"What are Batch Dimensions?","text":"Batch dimensions are additional dimensions beyond the standard spatial and coil dimensions:\n\n2D Imaging:\n\nSpatial: x, y, and slice if sensitivity maps are 3D\nCoil: coil\nBatch examples: [slice,] time, contrast, phase, etc.\n\n3D Imaging:\n\nSpatial: x, y, z\nCoil: coil\nBatch examples: time, contrast, phase, etc.","category":"section"},{"location":"high-level/decomposition/#Examples-of-Batch-Dimensions","page":"Problem Decomposition","title":"Examples of Batch Dimensions","text":"Multi-slice 2D:\n\nksp = rand(ComplexF32, 256, 256, 8, 20)  # (kx, ky, coil, slice)\n# Slice is a batch dimension - each slice independent\n\nDynamic 2D:\n\nksp = rand(ComplexF32, 256, 256, 8, 30)  # (kx, ky, coil, time)\n# Time is a batch dimension (if no temporal regularization)\n\nMulti-contrast 3D:\n\nksp = rand(ComplexF32, 128, 128, 64, 8, 4)  # (kx, ky, kz, coil, contrast)\n# Contrast is a batch dimension - each contrast independent\n\nNamed dimensions version:\n\nksp = NamedDimsArray{(:kx, :ky, :coil, :slice)}(...)\n# Automatically identifies :slice as batch dimension","category":"section"},{"location":"high-level/decomposition/#How-Regularization-Affects-Decomposition","page":"Problem Decomposition","title":"How Regularization Affects Decomposition","text":"","category":"section"},{"location":"high-level/decomposition/#Regularization-that-ALLOWS-Decomposition","page":"Problem Decomposition","title":"Regularization that ALLOWS Decomposition","text":"These regularizations only affect spatial dimensions:\n\n# Each time point reconstructed independently\nimg = reconstruct(acq_dynamic, L1Wavelet2D(5e-3))  # ‚úÖ Decomposed over time\n\n# Each slice reconstructed independently  \nimg = reconstruct(acq_multislice, TotalVariation2D(1e-3))  # ‚úÖ Decomposed over slices\n\n# Multiple spatial regularizers still allow decomposition\nimg = reconstruct(acq, (L1Wavelet2D(5e-3), TotalVariation2D(1e-3)))  # ‚úÖ Decomposed","category":"section"},{"location":"high-level/decomposition/#Regularization-that-PREVENTS-Decomposition","page":"Problem Decomposition","title":"Regularization that PREVENTS Decomposition","text":"These regularizations couple batch dimensions:\n\n# 3D wavelets couple slice dimension\nimg = reconstruct(acq_multislice, L1Wavelet3D(5e-3))  # ‚ùå No decomposition\n\n# Temporal regularization couples time points\nimg = reconstruct(acq_dynamic, TemporalFourier(1e-2))  # ‚ùå No decomposition\n\n# Low-rank couples time points\nimg = reconstruct(acq_dynamic, LowRank(1e-1))  # ‚ùå No decomposition","category":"section"},{"location":"high-level/decomposition/#Mixed-Cases","page":"Problem Decomposition","title":"Mixed Cases","text":"# Spatial + Temporal regularization\n# Cannot decompose over time (coupled by TemporalFourier)\n# But could decompose over other batch dimensions, like slice\nreg = (L1Wavelet2D(5e-3), TemporalFourier(1e-2))\nimg = reconstruct(acq, reg)  # Partial decomposition possible","category":"section"},{"location":"high-level/decomposition/#Controlling-Decomposition","page":"Problem Decomposition","title":"Controlling Decomposition","text":"","category":"section"},{"location":"high-level/decomposition/#Automatic-(Recommended)","page":"Problem Decomposition","title":"Automatic (Recommended)","text":"Just call reconstruct normally:\n\n# Automatic decomposition when beneficial\nimg = reconstruct(acq, L1Wavelet2D(5e-3))\n\nThe function will:\n\nAnalyze your data dimensions\nCheck if regularization allows decomposition\nAutomatically parallelize if beneficial\nUse all available CPU cores","category":"section"},{"location":"high-level/decomposition/#Manual-Control","page":"Problem Decomposition","title":"Manual Control","text":"Disable decomposition if needed:\n\n# Force sequential reconstruction\nimg = reconstruct(acq, regularization; \n                 disable_problem_decomposition=true)\n\nWhen to disable:\n\nDebugging (easier to trace single-threaded execution)\nLimited memory (decomposition uses more memory)\nBenchmarking specific aspects","category":"section"},{"location":"high-level/decomposition/#Choosing-Execution-Strategy","page":"Problem Decomposition","title":"Choosing Execution Strategy","text":"# Default: Multi-threading (recommended)\nimg = reconstruct(acq, reg)\n\n# Can explicitly specify executor\nusing MriReconstructionToolbox: MultiThreadingExecutor, SequentialExecutor\n\n# Force multi-threading\nimg = reconstruct(acq, reg; \n                 decomposition_executor=MultiThreadingExecutor())\n\n# Force sequential\nimg = reconstruct(acq, reg; \n                 decomposition_executor=SequentialExecutor())","category":"section"},{"location":"high-level/algorithms/#Optimization-Algorithms","page":"Optimization Algorithms","title":"Optimization Algorithms","text":"MriReconstructionToolbox supports multiple iterative optimization algorithms for solving MRI reconstruction problems. This guide helps you choose and configure the right algorithm for your needs.","category":"section"},{"location":"high-level/algorithms/#Quick-Algorithm-Selection","page":"Optimization Algorithms","title":"Quick Algorithm Selection","text":"Not sure which to use? Let reconstruct() choose automatically:\n\nimg = reconstruct(acq, regularization)\n# Automatically selects appropriate algorithm\n\nHow does it decides? Here's a decision tree:\n\nIs your problem smooth (no L1, TV, etc.)?\n‚îú‚îÄ Yes ‚Üí Use CGNR (Conjugate Gradient Normal Residual)\n‚îî‚îÄ No ‚Üí Does it have a single non-smooth regularizer where the wrapped operator is symmetric* (e.g. wavelets, temporal Fourier)?\n    ‚îú‚îÄ Yes ‚Üí Use FISTA (Fast Iterative Shrinkage-Thresholding Algorithm)\n    ‚îî‚îÄ No ‚Üí Use ADMM (Alternating Direction Method of Multipliers)\n\n*Symmetric means the operator satisfies E' * E = E * E', e.g. Fourier-based operators. But actually a more loose condition (is_AAc_diagonal from OperatorCore.jl) is used: E' * E = diag(d) for some d, i.e. the normal operator is equal to element-wise scaling.","category":"section"},{"location":"high-level/algorithms/#ProximalAlgorithms.jl-Interface","page":"Optimization Algorithms","title":"ProximalAlgorithms.jl Interface","text":"MriReconstructionToolbox builds on ProximalAlgorithms.jl. All algorithms from that package can be used directly. There are three recommended algorithms for MRI reconstruction used by default in reconstruct():\n\nCGNR: Conjugate Gradient Normal Residual for smooth problems\nFISTA: Fast Iterative Shrinkage-Thresholding Algorithm for single non-smooth regularizer\nADMM: Alternating Direction Method of Multipliers for multiple regularizers\n\nAll algorithms from this library share a common interface with the following parameters:\n\nmaxit::Int: maximum number of iteration\nstop::Function: termination condition, stop(::T, state) should return true when to stop the iteration\nsolution::Function: solution mapping, solution(::T, state) should return the identified solution\nverbose::Bool: whether the algorithm state should be displayed\nfreq::Int: every how many iterations to display the algorithm state\nsummary::Function: function returning a summary of the iteration state, summary(k::Int, iter::T, state) should return a vector of pairs (name, value)\ndisplay::Function: display function, display(k::Int, alg, iter::T, state) should display a summary of the iteration state","category":"section"},{"location":"high-level/algorithms/#Default-Algorithms","page":"Optimization Algorithms","title":"Default Algorithms","text":"","category":"section"},{"location":"high-level/algorithms/#Conjugate-Gradient-Normal-Residual-(CGNR)","page":"Optimization Algorithms","title":"Conjugate Gradient Normal Residual (CGNR)","text":"This algorithm solves linear systems of the form\n\nargmin‚Çì ‚ÄñAx - b‚Äñ‚ÇÇ¬≤ + ‚ÄñŒªx‚Äñ‚ÇÇ¬≤\n\nwhere A is a symmetric positive definite linear operator, and b is the measurement vector, and Œª is the L2 regularization parameter. Œª might be scalar or an array of the same size as x. If Œª is zero, the problem reduces to a least-squares problem:\n\nargmin‚Çì ‚ÄñAx - b‚Äñ‚ÇÇ¬≤\n\nBest for: Least-squares problems with optional Tikhonov regularization\n\nProperties:\n\nSolves normal equations: A'A¬∑x = A'¬∑b\nGood for ill-conditioned problems\nVariant of CG with different mathematical properties\n\nParameters:\n\nŒª=0: L2 regularization parameter (default: 0)\nP: preconditioner (optional)\nP_is_inverse: whether P is the inverse of the preconditioner (default: false)\n\nReferences:\n\nHestenes, M.R. and Stiefel, E., \"Methods of conjugate gradients for solving linear systems.\" Journal of Research of the National Bureau of Standards 49.6 (1952): 409-436.\n\nPros:\n\n‚úÖ Very fast convergence for appropriate problems\n‚úÖ No hyperparameter tuning\n‚úÖ Memory efficient\n\nCons:\n\n‚ùå Only for a small class of problems\n‚ùå Can't handle L1, TV, or other non-smooth terms\n\nExample:\n\nreconstruct(data, Tikhonov(1e-4), CGNR(maxit=2), verbose=false) # hide\nGC.gc() # hide\nimg = reconstruct(data, Tikhonov(1e-4), CGNR(maxit=20));\nnothing # hide","category":"section"},{"location":"high-level/algorithms/#Fast-Iterative-Shrinkage-Thresholding-Algorithm-(FISTA)","page":"Optimization Algorithms","title":"Fast Iterative Shrinkage-Thresholding Algorithm (FISTA)","text":"This algorithm solves convex optimization problems of the form\n\nminimize f(x) + g(x),\n\nwhere f is smooth.\n\nBest for: Single non-smooth regularizer (e.g. L1) with symmetric operator (e.g. wavelets)\n\nnote: Note\nFISTA is only an alias for FastForwardBackward from ProximalAlgorithms.jl.\n\nProperties:\n\nAccelerated gradient method\nHandles non-smooth regularization\nFaster convergence than basic ISTA\n\nParameters:\n\nmf=0: convexity modulus f (the smooth part of the objective, usually data fidelity term)\nLf=nothing: Lipschitz constant of the gradient of f (usually equals to 1 because the Lipschitz contant of squared L2 norm is 1 and get_encoding_operator returns a normalized operator)\ngamma=nothing: stepsize, defaults to 1/Lf if Lf is set, and nothing otherwise.\nadaptive=true: makes gamma adaptively adjust during the iterations; this is by default gamma === nothing.\nminimum_gamma=1e-7: lower bound to gamma in case adaptive == true.\nreduce_gamma=0.5: factor by which to reduce gamma in case adaptive == true, during backtracking.\nincrease_gamma=1.0: factor by which to increase gamma in case adaptive == true, before backtracking.\nextrapolation_sequence=nothing: sequence (iterator) of extrapolation coefficients to use for acceleration.\n\nReferences:\n\nTseng, \"On Accelerated Proximal Gradient Methods for Convex-Concave Optimization\" (2008).\nBeck, Teboulle, \"A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems\", SIAM Journal on Imaging Sciences, vol. 2, no. 1, pp. 183-202 (2009).\n\nPros:\n\n‚úÖ Fast for single regularizer\n‚úÖ Proven convergence guarantees\n‚úÖ Accelerated compared to basic gradient descent\n\nCons:\n\n‚ùå Only one regularizer\n‚ùå Requires Lipschitz constant (usually auto-estimated)\n‚ùå Can be sensitive to step size\n\nExample:\n\nreconstruct(data, L1Wavelet2D(5e-3), FISTA(maxit=2), verbose=false) # hide\nGC.gc() # hide\nimg = reconstruct(data, L1Wavelet2D(5e-3), FISTA(maxit=100));\nnothing # hide","category":"section"},{"location":"high-level/algorithms/#Alternating-Direction-Method-of-Multipliers-(ADMM)","page":"Optimization Algorithms","title":"Alternating Direction Method of Multipliers (ADMM)","text":"This algorithm solves optimization problems of the form\n\nminimize ¬Ω‚ÄñAx - b‚Äñ¬≤‚ÇÇ + ‚àë·µ¢ g·µ¢(B·µ¢x)\n\nwhere:\n\nA is a linear operator\nb is the measurement vector\ng·µ¢ are proximable functions with associated linear operators B·µ¢\n\nBest for: Multiple regularizers or complex constraints\n\nProperties:\n\nSplits problem into simpler subproblems\nHandles multiple regularizers naturally\nHandles contraints with non-symmetric operators (e.g. total variation)\n\nParameters:\n\nP=nothing: preconditioner for CG (optional)\nP_is_inverse=false: whether P is the inverse of the preconditioner\neps_abs=0: absolute tolerance for convergence\neps_rel=1: relative tolerance for convergence\ncg_tol=1e-6: CG tolerance\ncg_maxit=100: maximum CG iterations\ny0=nothing: initial dual variables\nz0=nothing: initial auxiliary variables\npenalty_sequence=nothing: penalty sequence for adaptive rho updating. The following options are available:\nFixedPenalty(rho): fixed penalty sequence with specified rho values\nResidualBalancingPenalty(rho; mu=10.0, tau=2.0): adaptive penalty sequence based on residual balancing [2]\nSpectralRadiusBoundPenalty(rho; tau=10.0, eta=100.0): adaptive penalty sequence based on spectral radius bounds [3]\nSpectralRadiusApproximationPenalty(rho; tau=10.0): adaptive penalty sequence based on spectral radius approximation [4]\nNote: rho can be specified either as the rho parameter or within the penalty sequence constructor, but not both.\n\nThe adaptive penalty parameter schemes are implemented through the penalty sequence types,  following various strategies from the literature. See the individual penalty sequence types  for their specific update rules and references.\n\nReferences:\n\nBoyd, S., Parikh, N., Chu, E., Peleato, B., & Eckstein, J. (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning, 3(1), 1-122.\nHe, B. S., Yang, H., & Wang, S. L. (2000). Alternating direction method with self-adaptive penalty parameters for monotone variational inequalities. Journal of Optimization Theory and applications, 106(2), 337-356.\nLorenz, D. A., & Tran-Dinh, Q. (2019). Non-stationary Douglas‚ÄìRachford and alternating direction method of multipliers: Adaptive step-sizes and convergence. Computational Optimization and Applications, 74(1), 67‚Äì92. https://doi.org/10.1007/s10589-019-00106-9\nMccann, M. T., & Wohlberg, B. (2024). Robust and Simple ADMM Penalty Parameter Selection. IEEE Open Journal of Signal Processing, 5, 402‚Äì420. https://doi.org/10.1109/OJSP.2023.3349115\n\nPros:\n\n‚úÖ Handles multiple regularizers\n‚úÖ Very robust and stable\n‚úÖ Good for complex problems\n\nCons:\n\n‚ùå Slower than FISTA for single regularizer\n‚ùå More parameters to tune\n‚ùå Each iteration more expensive\n‚ùå No convergence guarantees in general\n\nExample:\n\n# Multiple regularizers\nreg = (L1Wavelet2D(5e-3), TotalVariation2D(1e-3))\nreconstruct(data, reg, ADMM(maxit=2), verbose=false) # hide\nGC.gc() # hide\nimg = reconstruct(data, reg, ADMM(maxit=50));\nnothing # hide","category":"section"},{"location":"high-level/algorithms/#Tuning-Algorithm-Parameters","page":"Optimization Algorithms","title":"Tuning Algorithm Parameters","text":"","category":"section"},{"location":"high-level/algorithms/#Maximum-Iterations","page":"Optimization Algorithms","title":"Maximum Iterations","text":"How many iterations do you need?\n\nTypical ranges:\n\nCG/CGNR: 10-50 iterations\nFISTA: 50-200 iterations\nADMM: 20-100 iterations\n\nStrategy:\n\n# Start with more iterations to see convergence behavior\nimg = reconstruct(acq, reg, FISTA(maxit=200), verbose=true)\n# Check output to see when convergence plateaus\n\n# Then use fewer iterations in production\nimg = reconstruct(acq, reg, FISTA(maxit=80))","category":"section"},{"location":"high-level/algorithms/#Convergence-Tolerance","page":"Optimization Algorithms","title":"Convergence Tolerance","text":"Controls early stopping:\n\n# Stricter convergence\nimg = reconstruct(acq, reg, FISTA(maxit=200, tol=1e-6))\n\n# Looser convergence (faster but less accurate)\nimg = reconstruct(acq, reg, FISTA(maxit=200, tol=1e-3))\n\n# Disable early stopping\nimg = reconstruct(acq, reg, FISTA(maxit=100, tol=0))\n\nPractical tip: Default tol=1e-4 is usually good. Tighten to 1e-5 or 1e-6 if you need higher accuracy.","category":"section"},{"location":"high-level/algorithms/#Verbosity-and-Monitoring","page":"Optimization Algorithms","title":"Verbosity and Monitoring","text":"Track convergence:\n\n# Show progress every iteration\nimg = reconstruct(acq, reg, algorithm; verbose=true, freq=1)\n\n# Show progress every 10 iterations\nimg = reconstruct(acq, reg, algorithm; verbose=true, freq=10)\n\n# No output\nimg = reconstruct(acq, reg, algorithm; verbose=false)\n\nWhat to look for:\n\nObjective value decreasing\nChanges becoming smaller\nReasonable convergence rate","category":"section"},{"location":"high-level/algorithms/#Advanced-Usage","page":"Optimization Algorithms","title":"Advanced Usage","text":"","category":"section"},{"location":"high-level/algorithms/#Auto-Selecting-Multiple-Algorithms","page":"Optimization Algorithms","title":"Auto-Selecting Multiple Algorithms","text":"Try multiple algorithms automatically:\n\n# Provide tuple of algorithms to try\nalgorithms = (CG(maxit=20), FISTA(maxit=100), ADMM(maxit=50))\nimg = reconstruct(acq, reg, algorithms)\n\n# Package automatically selects best for problem\n# - CG tried first for smooth problems\n# - FISTA for single regularizer\n# - ADMM for multiple regularizers","category":"section"},{"location":"high-level/algorithms/#Custom-Stopping-Criteria","page":"Optimization Algorithms","title":"Custom Stopping Criteria","text":"using ProximalAlgorithms\n\n# Custom stopping function\nfunction my_stop(iter, state)\n    # Stop if objective doesn't change much\n    if iter > 1\n        rel_change = abs(state.objective - prev_obj) / abs(prev_obj)\n        return rel_change < 1e-5\n    end\n    prev_obj = state.objective\n    return false\nend\n\n# Use with low-level interface\n# (requires working directly with ProximalAlgorithms.jl)","category":"section"},{"location":"high-level/algorithms/#Warm-Starting","page":"Optimization Algorithms","title":"Warm Starting","text":"Use previous solution as initialization:\n\n# First reconstruction\nimg1 = reconstruct(acq, L1Wavelet2D(5e-3))\n\n# Use as initialization for refined reconstruction\nimg2 = reconstruct(acq, L1Wavelet2D(3e-3); x‚ÇÄ=img1)\n\nWhen useful:\n\nParameter sweeps\nIterative refinement\nMulti-stage reconstruction","category":"section"},{"location":"low-level/custom_reconstruction/#Custom-Reconstruction-with-StructuredOptimization","page":"Custom Reconstruction","title":"Custom Reconstruction with StructuredOptimization","text":"This page shows how to experiment with custom reconstruction problems using StructuredOptimization.jl, leveraging its convenient bindings to AbstractOperators.jl (operators like FFT, Wavelets, reshape, slicing) and ProximalOperators.jl (norms and penalties with fast proximal maps).","category":"section"},{"location":"low-level/custom_reconstruction/#Essentials","page":"Custom Reconstruction","title":"Essentials","text":"Variable: declares decision variables (scalars, vectors, matrices, tensors).\n@minimize: builds and solves an optimization problem from expressions.\nproblem(...) and StructuredOptimization.parse_problem(...): build and inspect the parsed problem for a given algorithm.\nConvenient bindings:\nSmooth terms: ls(ex) for 1/2||ex||^2\nNonsmooth norms: norm(ex, 1), norm(ex, 2), norm(ex, Inf), mixed norm(ex, 2, 1), nuclear norm norm(ex, *)\nOperator composition: op * expr, reshape(expr, ...), fft, dct, finitediff, etc.","category":"section"},{"location":"low-level/custom_reconstruction/#Two-Variable-Example:-Sparse-Low-Rank-Wavelet-Prior","page":"Custom Reconstruction","title":"Two-Variable Example: Sparse + Low-Rank Wavelet Prior","text":"We build a toy reconstruction with two variables and two regularizers:\n\nVariable x: L1 sparsity prior.\nVariable z: nuclear norm prior after a wavelet transform and reshaping to a matrix.\nData fidelity: simple least-squares to synthetic observation b.\n\nusing StructuredOptimization\nusing AbstractOperators\nusing ProximalOperators\nusing WaveletOperators: WaveletOp, WT, wavelet\nusing SparseArrays: sprandn\nusing ProximalAlgorithms: FastForwardBackward, PANOCplus\n\n# Problem size (kept small for docs)\nnx, ny = 32, 32\n\n# Variables\nx = Variable(nx, ny)           # sparse image component\nz = Variable(nx, ny)           # low-rank (after transform) component\n\n# Synthetic observation b = x* + z* + small noise (unknown in practice)\nx_true = sprandn(nx, ny, 0.1)\nz_true = randn(nx, ny) .* 0.1\nb = x_true + z_true + 0.01 .* randn(nx, ny)\n\n# Wavelet transform operator (orthonormal, tight frame)\nW = WaveletOp(Float64, wavelet(WT.db4), (nx, ny))\n\n# Regularization strengths\nŒª1 = 0.05\nŒª2 = 0.2\n\n# Build problem:\n#   min_{x,z} 1/2 || (x + z) - b ||^2 + Œª2 * nuclearnorm( W*z ) s.t. norm(x, 0) < 50\n# It is hard to solve, so first we solve a relaxed version without the L0 constraint:\n#   min_{x,z} 1/2 || (x + z) - b ||^2 + Œª1 * norm(x, 1) + Œª2 * nuclearnorm( W*z )\n# Bindings used:\n#   - ls(...)       -> least-squares\n#   - norm(.,0)     -> L0 \"norm\" (count of nonzeros)\n#   - norm(., 1)    -> L1 norm\n#   - norm(., *)    -> nuclear norm (sum of singular values)\n#   - W * z         -> operator application\n\n# Parse first (inspect what a solver expects) -- optional, only for demonstration\np = problem( ls(x + z - b), Œª2 * norm(W * z, *), norm(x, 0) <= 50 )\nalg, kwargs, vars = StructuredOptimization.parse_problem(p, PANOCplus())\nprintln(\"Prepared keys for PANOCplus: \", keys(kwargs))\n\n# Solve relaxed problem with FISTA\n(xÃÇ, zÃÇ), it = @minimize ls(x + z - b) + Œª1 * norm(x, 1) + Œª2 * norm(W * z, *) with FastForwardBackward(maxit=50, verbose=false)\nprintln(\"FISTA Iterations (relaxed problem): \", it)\n# Solve original problem with PANOCplus\n(xÃÇ, zÃÇ), it = @minimize ls(x + z - b) + Œª2 * norm(W * z, *) st norm(x, 0) <= 50 with PANOCplus(maxit=20, tol=1e-6, verbose=false)\nprintln(\"Iterations: \", it)\nprintln(\"Solution sizes: \", size(~xÃÇ), \", \", size(~zÃÇ))\n\n# Quick sanity: objective components (not rigorous tests)\nval_l1 = NormL0(Œª1)(~xÃÇ)\n# For nuclear norm value evaluate explicitly on the reshaped transform\nusing LinearAlgebra\nS = svdvals(W * ~zÃÇ)\nval_nuc = Œª2 * sum(S)\nprintln(\"L1 term: \", round(val_l1, digits=4), \"; Nuclear term: \", round(val_nuc, digits=4))","category":"section"},{"location":"low-level/custom_reconstruction/#What-Just-Happened","page":"Custom Reconstruction","title":"What Just Happened","text":"ls(x + z - b) is the data fidelity term.\nnorm(x, 1) applies the L1 norm to x via ProximalOperators.NormL1.\nnorm(., 0) applies the L0 \"norm\" (count of nonzeros) via ProximalOperators.NormL0.\nnorm(W*z, *) applies the nuclear norm through a Term(NuclearNorm(), ...) binding; the reshape ensures a matrix domain.\nW is an orthonormal/Parseval wavelet transform (tight frame), enabling efficient proximal splitting.\nThe problem separates across variables (x and z), so FISTA (= FastForwardBackward) can handle both nonsmooth terms.","category":"section"},{"location":"low-level/custom_reconstruction/#Anatomy:-Basics-in-One-Place","page":"Custom Reconstruction","title":"Anatomy: Basics in One Place","text":"using StructuredOptimization\nusing AbstractOperators\nusing ProximalOperators\nusing ProximalAlgorithms: FastForwardBackward\n\n# Variables and access\nu = Variable(10); v = Variable(10)\n\n# Smooth term (LS)\nterm_smooth = ls(u + v - randn(10))\n\n# Common nonsmooths\nterm_l1  = norm(u, 1)        # L1\nterm_l2  = norm(v, 2)        # L2\nterm_l21 = norm(reshape(v, 2, 5), 2, 1)  # group sparsity\nterm_nuc = norm(reshape(v, 5, 2), *)     # nuclear\n\n# AbstractOperators bindings\nex_fft  = fft(u)   # Fourier transform binding\nex_resh = reshape(ex_fft, 5, 2)                   # reshape expression\n\n# Build and solve explicitly via `problem` + `solve`\nq = problem(term_smooth, 0.1*term_l1, 0.05*term_nuc)\nsol, it2 = solve(q, FastForwardBackward(maxit=50, verbose=false))\nprintln(\"Solved in \", it2, \" iterations. Size(~u): \", size(~u))","category":"section"},{"location":"low-level/custom_reconstruction/#Where-to-Go-Next","page":"Custom Reconstruction","title":"Where to Go Next","text":"More norms and penalties: see low-level/proximal_operators.md.\nOperator catalog and composition patterns: see low-level/abstract_operators.md and low-level/operators.md.\nFor full MRI forward models and reconstruction entry points, see high-level/reconstruction.md.","category":"section"},{"location":"low-level/custom_reconstruction/#See-Also","page":"Custom Reconstruction","title":"See Also","text":"ProximalOperators.jl Summary: list of common proximal functions and custom implementation pattern.\nAbstractOperators.jl Summary: base operator abstractions and composition rules.\nMRI Operators: concrete Fourier, sensitivity map, and subsampling operators.\nHigh level Reconstruction: unified reconstruction interface tying everything together.","category":"section"},{"location":"#MriReconstructionToolbox.jl","page":"Home","title":"MriReconstructionToolbox.jl","text":"A comprehensive Julia package for MRI reconstruction\n\nMriReconstructionToolbox.jl provides everything you need to reconstruct images from MRI k-space data, from simple FFT-based reconstruction to advanced compressed sensing with sophisticated regularization.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"Note: This package is not yet registered in the Julia General registry because it needs enhancements to upstream packages. These changes are currently under pull requests, and hopefully will be merged soon. Installation requires adding dependencies from GitHub repositories:\n\nusing Pkg\n\n# Add the package from GitHub\nPkg.add(url=\"https://github.com/hakkelt/AbstractOperators.jl\")\nPkg.add(url=\"https://github.com/hakkelt/AbstractOperators.jl\", subdir=\"FFTWOperators\")\nPkg.add(url=\"https://github.com/hakkelt/AbstractOperators.jl\", subdir=\"DSPOperators\")\nPkg.add(url=\"https://github.com/hakkelt/AbstractOperators.jl\", subdir=\"NFFTOperators\")\nPkg.add(url=\"https://github.com/hakkelt/AbstractOperators.jl\", subdir=\"WaveletOperators\")\nPkg.add(url=\"https://github.com/hakkelt/ProximalCore.jl\")\nPkg.add(url=\"https://github.com/hakkelt/ProximalOperators.jl\")\nPkg.add(url=\"https://github.com/hakkelt/ProximalAlgorithms.jl\")\nPkg.add(url=\"https://github.com/hakkelt/StructuredOptimization.jl\")\nPkg.add(url=\"https://github.com/hakkelt/MriReconstructionToolbox.jl\")","category":"section"},{"location":"#What-This-Package-Does","page":"Home","title":"What This Package Does","text":"MriReconstructionToolbox.jl solves the MRI reconstruction inverse problem:\n\nGiven: k-space measurements (undersampled, multi-coil)\nFind: Image that best explains the measurements\n\nThe package provides:\n\nComplete MRI Forward Model: Models the entire acquisition chain\nFlexible Regularization: Multiple methods for different image properties\nEfficient Algorithms: Many iterative solvers from ProximalAlgorithms.jl\nHigh-Level Interface: Simple reconstruct() function for common tasks\nLow-Level Control: Direct operator access for custom algorithms","category":"section"},{"location":"#Features","page":"Home","title":"Features","text":"‚úÖ Complete MRI Forward Model - Fourier transform + sensitivity maps + subsampling\n‚úÖ Parallel Imaging - Multi-coil reconstruction with sensitivity maps\n‚úÖ Compressed Sensing - Advanced undersampling and regularization\n‚úÖ Multiple Regularizers - Sparsity, wavelets, total variation, low-rank\n‚úÖ Fast Algorithms - FISTA, ADMM, Conjugate Gradient\n‚úÖ Auto-Parallelization - Automatic decomposition over batch dimensions\n‚úÖ Named Dimensions - Type-safe interface prevents dimension errors\n‚úÖ Simulation Tools - Built-in phantoms and sampling patterns\n‚úÖ High Performance - Multi-threaded FFTs and optimized operators","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"#Simulation-Example","page":"Home","title":"Simulation Example","text":"","category":"section"},{"location":"#Shepp-Logan-Phantom-and-Noisy-Observation","page":"Home","title":"Shepp-Logan Phantom and Noisy Observation","text":"using MriReconstructionToolbox\nusing MIRTjim: jim\n\nnx, ny, nc = 256, 256, 8\nx·µç·µó = shepp_logan(nx, ny)\nnoise_level = 0.03f0\nx = x·µç·µó + noise_level * randn(ComplexF32, nx, ny)\np1 = jim(x·µç·µó; title = \"Ground truth\")\np2 = jim(x; title = \"Noisy image\")\njim(p1, p2; layout = (1, 2), size = (700, 300))\nsavefig(\"shepp_logan_noisy.png\"); nothing # hide\n\n(Image: shepp_logan_noisy.png)","category":"section"},{"location":"#Coil-Sensitivity-Maps","page":"Home","title":"Coil Sensitivity Maps","text":"smaps = coil_sensitivities(nx, ny, nc)\njim(smaps; title = \"Coil sensitivity maps\", nrow=1, size = (1400, 200))\nsavefig(\"coil_sensitivity_maps.png\"); nothing # hide\n\n(Image: coil_sensitivity_maps.png)","category":"section"},{"location":"#k-space-Undersampling-Pattern","page":"Home","title":"k-space Undersampling Pattern","text":"using Plots\n\npdf = VariableDensitySampling(PolynomialDistribution(3), 3.0, 0.1)\nW = MriReconstructionToolbox.construct_weights(pdf, (nx,))\np1 = plot(W; title = \"1D Sampling weights\", legend = false)\n\npattern = create_sampling_pattern(pdf, (nx, ny))\np2 = jim(to_displayable_mask(pattern, (nx, ny)); title = \"Sampling pattern\")\n\njim(p1, p2; layout = (1, 2), size = (700, 300))\nsavefig(\"sampling_pattern.png\"); nothing # hide\n\n(Image: sampling_pattern.png)","category":"section"},{"location":"#Simulation-of-Acquisition","page":"Home","title":"Simulation of Acquisition","text":"# Create acquisition info that contains every knowledge about the acquisition, but no actual data yet\nacq_info = AcquisitionInfo(\n   is3D=false,\n   image_size=(nx, ny),\n   subsampling=pattern,\n   sensitivity_maps=smaps)\n\n# Simulate k-space acquisition\ndata = simulate_acquisition(x, acq_info)","category":"section"},{"location":"#Reconstruction-Examples","page":"Home","title":"Reconstruction Examples","text":"","category":"section"},{"location":"#Direct-Reconstruction-via-Adjoint","page":"Home","title":"Direct Reconstruction via Adjoint","text":"reconstruct(data, verbose=false); # hide\nxÃÇ_direct = reconstruct(data)\np1 = jim(xÃÇ_direct; title = \"Direct reconstruction\")\np2 = jim(abs.(xÃÇ_direct - x·µç·µó); title = \"Error map\")\njim(p1, p2; layout = (1, 2), size = (700, 300))\nsavefig(\"direct_reconstruction.png\"); nothing # hide\n\n(Image: direct_reconstruction.png)","category":"section"},{"location":"#Compressed-Sensing-Reconstruction-with-Wavelet-Regularization","page":"Home","title":"Compressed Sensing Reconstruction with Wavelet Regularization","text":"reg = L1Wavelet2D(0.01f0)\nreconstruct(data, reg; maxit=3, verbose=false) # hide\nxÃÇ_cs = reconstruct(data, reg; maxit=50)\np1 = jim(xÃÇ_cs; title = \"CS Reconstruction\")\np2 = jim(abs.(xÃÇ_cs - x·µç·µó); title = \"Error map\")\njim(p1, p2; layout = (1, 2), size = (700, 300))\nsavefig(\"cs_reconstruction.png\"); nothing # hide\n\n(Image: cs_reconstruction.png)","category":"section"},{"location":"#Custom-Reconstruction-With-Low-Level-Interface","page":"Home","title":"Custom Reconstruction With Low-Level Interface","text":"# Prepare encoding operator\n‚Ñ≥ = get_subsampling_operator(data)\n‚Ñ± = get_fourier_operator(data)\nùíÆ = get_sensitivity_map_operator(data)\nùíú = ‚Ñ≥ * ‚Ñ± * ùíÆ\n\n# Get k-space data and direct reconstruction\nb = data.kspace_data\nxÃÇ = ùíú' * b # direct reconstruction as adjoint operation\np1 = jim(xÃÇ; title = \"Direct reconstruction\")\np2 = jim(abs.(xÃÇ - x·µç·µó); title = \"Error map\")\njim(p1, p2; layout = (1, 2), size = (700, 300))\nsavefig(\"direct_reconstruction_lowlevel.png\"); nothing # hide\n\n(Image: direct_reconstruction_lowlevel.png)\n\n# Set up and solve custom optimization problem with StructuredOptimization.jl\nv = Variable(xÃÇ); # use direct reconstruction as initial guess\nùí≤ = WaveletOp(ComplexF32, wavelet(WT.db4), (nx, ny))\nalg = FISTA(maxit=50, verbose=true, freq=5)\nxÃÇ_custom, it = @minimize ls(ùíú * v - b) + 0.01 * norm(ùí≤ * v, 1) with alg\n\n# Visualize results\nprintln(\"Reconstruction completed in $it iterations.\")\np1 = jim(~xÃÇ_custom; title = \"CS Reconstruction\")\np2 = jim(abs.(~xÃÇ_custom - x·µç·µó); title = \"Error map\")\njim(p1, p2; layout = (1, 2), size = (700, 300))\nsavefig(\"custom_cs_reconstruction.png\"); nothing # hide\n\n(Image: custom_cs_reconstruction.png)","category":"section"},{"location":"high-level/simulation/#Simulation-Tools","page":"Simulation Tools","title":"Simulation Tools","text":"MriReconstructionToolbox provides comprehensive tools for simulating MRI acquisitions. These are essential for testing reconstruction algorithms, teaching MRI concepts, and prototyping new acquisition strategies.","category":"section"},{"location":"high-level/simulation/#Why-Simulate?","page":"Simulation Tools","title":"Why Simulate?","text":"Simulation is useful for:\n\nTesting reconstruction algorithms without needing real MRI data\nUnderstanding MRI physics through hands-on experimentation\nPrototyping new acquisition strategies before scanner implementation\nTeaching and learning MRI concepts interactively\nBenchmarking reconstruction methods with known ground truth","category":"section"},{"location":"high-level/simulation/#Overview:-Complete-Simulation-Pipeline","page":"Simulation Tools","title":"Overview: Complete Simulation Pipeline","text":"A typical simulation workflow:\n\nusing MriReconstructionToolbox\n\n# 1. Create a phantom (ground truth image)\nimg = shepp_logan(256, 256)\n\n# 2. Generate coil sensitivity maps\nsmaps = coil_sensitivities(256, 256, 8)\n\n# 3. Create a subsampling pattern\npdf = VariableDensitySampling(PolynomialDistribution(3), 3.0, 0.1)\npattern = create_sampling_pattern(pdf, (256, 256))\n\n# 4. Simulate the acquisition\nacq = AcquisitionInfo(is3D=false,\n                      sensitivity_maps=smaps,\n                      subsampling=pattern)\nacq_with_data = simulate_acquisition(img, acq)\n\n# 5. Reconstruct and compare\nimg_recon = reconstruct(acq_with_data, L1Wavelet2D(5e-3), verbose=false)\nnothing # hide","category":"section"},{"location":"high-level/simulation/#Phantoms","page":"Simulation Tools","title":"Phantoms","text":"Phantoms are synthetic images that serve as ground truth for testing.","category":"section"},{"location":"high-level/simulation/#Shepp-Logan-Phantom","page":"Simulation Tools","title":"Shepp-Logan Phantom","text":"The classic test phantom for MRI reconstruction.\n\nusing MIRTjim: jim\n\n# 2D Shepp-Logan\nimg = shepp_logan(256, 256)  # Returns ComplexF32 array\n\n# 3D Shepp-Logan\nimg_3d = shepp_logan(128, 128, 64)\njim(img_3d; title=\"Shepp-Logan Phantom\", nrow=4, size=(1200,300))\nsavefig(\"3D_shepp_logan_phantom.png\"); nothing # hide\n\n(Image: 3D_shepp_logan_phantom.png)","category":"section"},{"location":"high-level/simulation/#Coil-Sensitivity-Maps","page":"Simulation Tools","title":"Coil Sensitivity Maps","text":"Sensitivity maps model the spatial response of receiver coils in parallel imaging.\n\n# Generate sensitivity maps for 8 coils\nsmaps = coil_sensitivities(256, 256, 8)\n\n# 3D sensitivity maps\nsmaps_3d = coil_sensitivities(128, 128, 64, 8)\n\n# Visualize 2D coil sensitivities\njim(smaps; title=\"Coil Sensitivity Maps\", nrow=1, size=(1400, 200))\nsavefig(\"coil_sensitivity_maps.png\"); nothing # hide\n\n(Image: coil_sensitivity_maps.png)\n\nWhat you get:\n\nSmooth, realistic sensitivity patterns\nEach coil has higher sensitivity near its location\nProper phase variations\nReturns ComplexF32 array with shape (nx, ny, [nz,] ncoils)","category":"section"},{"location":"high-level/simulation/#Subsampling-Patterns","page":"Simulation Tools","title":"Subsampling Patterns","text":"Subsampling patterns determine which k-space locations are measured.","category":"section"},{"location":"high-level/simulation/#Uniform-Cartesian-Sampling","page":"Simulation Tools","title":"Uniform Cartesian Sampling","text":"","category":"section"},{"location":"high-level/simulation/#Example:-2D-Uniform-Random-Sampling","page":"Simulation Tools","title":"Example: 2D Uniform Random Sampling","text":"using Plots\n\n# Center fraction = 0.1 (10% fully sampled center, default)\npdf = UniformRandomSampling(3.0)\npattern = create_sampling_pattern(pdf, (256, 256))\np1 = jim(to_displayable_mask(pattern, (256, 256)); title = \"cf=0.1\")\n\n# Center fraction = 0.3 (30% fully sampled center)\npdf = UniformRandomSampling(3.0, 0.3)\npattern = create_sampling_pattern(pdf, (256, 256))\np2 = jim(to_displayable_mask(pattern, (256, 256)); title = \"cf=0.3\")\n\n# 2D subsampling: freq encoding also subsampled (not realistic, for demo)\npdf = UniformRandomSampling(3.0)\npattern = create_sampling_pattern(pdf, (256, 256), subsample_freq_encoding=true)\np3 = jim(to_displayable_mask(pattern, (256, 256)); title = \"Freq encoding subsampled\")\n\njim(p1, p2, p3; layout = (1, 3), size = (1000, 300))\nsavefig(\"2D_uniform_random_sampling_weights.png\"); nothing # hide\n\n(Image: 2D_uniform_random_sampling_weights.png)","category":"section"},{"location":"high-level/simulation/#Example:-3D-Uniform-Random-Sampling","page":"Simulation Tools","title":"Example: 3D Uniform Random Sampling","text":"pdf = UniformRandomSampling(4.0, 0.1)\npattern_3d = create_sampling_pattern(pdf, (128, 128, 64))\nmask = zeros(Bool, 128, 128, 64)\nmask[pattern_3d...] .= true\np1 = jim(mask[:, :, 32]; title=\"x-y plane\")\np2 = jim(mask[:, 64, :]; title=\"x-z plane\")\np3 = jim(mask[64, :, :]; title=\"y-z plane\")\njim(p1, p2, p3; layout=(1,3), size=(1000,300))\nsavefig(\"3D_uniform_random_sampling_weights.png\"); nothing # hide\n\n(Image: 3D_uniform_random_sampling_weights.png)","category":"section"},{"location":"high-level/simulation/#Variable-Density-Sampling","page":"Simulation Tools","title":"Variable Density Sampling","text":"The most common pattern for compressed sensing. There are many options for generating variable density patterns.","category":"section"},{"location":"high-level/simulation/#Example:-Different-Variable-Density-Patterns-in-2D","page":"Simulation Tools","title":"Example: Different Variable Density Patterns in 2D","text":"gaussian_pdf‚ÇÅ = VariableDensitySampling(GaussianDistribution(1/3), 3.0)\ngaussian_pattern‚ÇÅ = create_sampling_pattern(gaussian_pdf‚ÇÅ, (256, 256))\nW = MriReconstructionToolbox.construct_weights(gaussian_pdf‚ÇÅ, (256,))\n\np1 = plot(W; legend = false)\np2 = jim(to_displayable_mask(gaussian_pattern‚ÇÅ, (256, 256)))\njim(p1, p2; layout=(1,2), plot_title=\"Gaussian std=1/3\", size = (700, 300))\nsavefig(\"gaussian_sampling_pattern_1.png\"); nothing # hide\n\n(Image: gaussian_sampling_pattern_1.png)\n\ngaussian_pdf‚ÇÇ = VariableDensitySampling(GaussianDistribution(1/5), 3.0)\ngaussian_pattern‚ÇÇ = create_sampling_pattern(gaussian_pdf‚ÇÇ, (256, 256))\nW = MriReconstructionToolbox.construct_weights(gaussian_pdf‚ÇÇ, (256,))\n\np1 = plot(W; legend = false)\np2 = jim(to_displayable_mask(gaussian_pattern‚ÇÇ, (256, 256)))\njim(p1, p2; layout=(1,2), plot_title=\"Gaussian std=1/5\", size = (700, 300))\nsavefig(\"gaussian_sampling_pattern_2.png\"); nothing # hide\n\n(Image: gaussian_sampling_pattern_2.png)\n\npoly_pdf‚ÇÅ = VariableDensitySampling(PolynomialDistribution(2), 3.0)\npoly_pattern‚ÇÅ = create_sampling_pattern(poly_pdf‚ÇÅ, (256, 256))\n\nW = MriReconstructionToolbox.construct_weights(poly_pdf‚ÇÅ, (256,))\np1 = plot(W; legend = false)\np2 = jim(to_displayable_mask(poly_pattern‚ÇÅ, (256, 256)))\njim(p1, p2; layout=(1,2), plot_title=\"Polynomial p=2\", size = (700, 300))\nsavefig(\"polynomial_sampling_pattern_1.png\"); nothing # hide\n\n(Image: polynomial_sampling_pattern_1.png)\n\npoly_pdf‚ÇÇ = VariableDensitySampling(PolynomialDistribution(4), 3.0)\npoly_pattern‚ÇÇ = create_sampling_pattern(poly_pdf‚ÇÇ, (256, 256))\nW = MriReconstructionToolbox.construct_weights(poly_pdf‚ÇÇ, (256,))\np1 = plot(W; legend = false)\np2 = jim(to_displayable_mask(poly_pattern‚ÇÇ, (256, 256)))\njim(p1, p2; layout=(1,2), plot_title=\"Polynomial p=4\", size = (700, 300))\nsavefig(\"polynomial_sampling_pattern_2.png\"); nothing # hide\n\n(Image: polynomial_sampling_pattern_2.png)","category":"section"},{"location":"high-level/simulation/#Example:-Variable-Density-in-3D","page":"Simulation Tools","title":"Example: Variable Density in 3D","text":"poly_pdf = VariableDensitySampling(PolynomialDistribution(2), 3.0)\npoly_pattern = create_sampling_pattern(poly_pdf, (256, 256, 256))\nmask = zeros(Bool, 256, 256, 256)\nmask[poly_pattern...] .= true\np1 = jim(mask[:, :, 128]; title=\"x-y plane\")\np2 = jim(mask[:, 128, :]; title=\"x-z plane\")\np3 = jim(mask[128, :, :]; title=\"y-z plane\")\njim(p1, p2, p3; layout=(1,3), size=(900,200))\nsavefig(\"3D_variable_density_sampling_weights.png\"); nothing # hide\n\n(Image: 3D_variable_density_sampling_weights.png)","category":"section"},{"location":"high-level/simulation/#Poisson-Disk-Sampling","page":"Simulation Tools","title":"Poisson Disk Sampling","text":"Spatially uniform but avoiding clustering.\n\npdf = PoissonDiskSampling(3.0)\npattern = create_sampling_pattern(pdf, (256, 256), subsample_freq_encoding=true)\njim(to_displayable_mask(pattern, (256, 256)); title=\"Poisson Disk Sampling\", size = (300, 300))\nsavefig(\"poisson_disk_sampling_pattern.png\"); nothing # hide\n\n(Image: poisson_disk_sampling_pattern.png)\n\nProperties:\n\nMaintains minimum distance between samples\nMore uniform coverage than random\nGood incoherence properties","category":"section"},{"location":"high-level/simulation/#Simulate-Acquisition","page":"Simulation Tools","title":"Simulate Acquisition","text":"","category":"section"},{"location":"high-level/simulation/#Advanced-Simulation","page":"Simulation Tools","title":"Advanced Simulation","text":"","category":"section"},{"location":"high-level/simulation/#Adding-Noise","page":"Simulation Tools","title":"Adding Noise","text":"# Simulate acquisition\nacq = simulate_acquisition(img_true, acq)\n\n# Add Gaussian noise to k-space\nnoise_level = 0.01  # Adjust based on desired SNR\nnoise = noise_level * randn(ComplexF32, size(acq.kspace_data))\nacq = AcquisitionInfo(acq; kspace_data=acq.kspace_data .+ noise)\n\n# Reconstruct noisy data\nimg_recon = reconstruct(acq, L1Wavelet2D(5e-3))","category":"section"},{"location":"high-level/simulation/#Custom-Subsampling-Patterns","page":"Simulation Tools","title":"Custom Subsampling Patterns","text":"# Manual pattern creation\nmask = falses(256, 256)\n\n# Fully sample center\nmask[118:138, 118:138] .= true\n\n# Random sampling elsewhere\nfor i in 1:256, j in 1:256\n    if !mask[i,j] && rand() < 0.2  # 20% sampling\n        mask[i,j] = true\n    end\nend\n\n# Use custom mask\nacq = AcquisitionInfo(img, false; subsampling=mask)","category":"section"},{"location":"high-level/simulation/#Cartesian-Line-Sampling","page":"Simulation Tools","title":"Cartesian Line Sampling","text":"# Sample every 4th phase encoding line\nny = 256\nlines_to_sample = [1:4:ny; div(ny,2)-10:div(ny,2)+10]  # Skip plus center\n\nmask = falses(256, 256)\nmask[:, lines_to_sample] .= true\n\nacq = AcquisitionInfo(img, false; subsampling=mask)","category":"section"},{"location":"high-level/simulation/#MriReconstructionToolbox.shepp_logan","page":"Simulation Tools","title":"MriReconstructionToolbox.shepp_logan","text":"shepp_logan(nx::Int, ny::Int; oversample=3) -> Array{ComplexF32, 2}\nshepp_logan(nx::Int, ny::Int, nz::Int; oversample=3) -> Array{ComplexF32, 3}\n\nGenerate a Shepp-Logan phantom for MRI simulation and reconstruction testing.\n\nThe Shepp-Logan phantom is a standard test image widely used in medical imaging research, particularly for MRI and CT reconstruction algorithm validation. This implementation uses the Toft modification of the original Shepp-Logan phantom, which provides better contrast for modern reconstruction algorithms.\n\nArguments\n\nnx::Int: Number of pixels/voxels in the x-dimension\nny::Int: Number of pixels/voxels in the y-dimension\nnz::Int: (3D only) Number of voxels in the z-dimension\n\nKeywords\n\noversample::Int=3: Oversampling factor for anti-aliasing. Higher values produce smoother edges but take longer to compute. Default of 3 provides good quality for most applications.\n\nReturns\n\n2D: A ComplexF32 matrix of size (nx, ny) representing the phantom image\n3D: A ComplexF32 array of size (nx, ny, nz) representing the phantom volume\n\nDetails\n\n2D Phantom\n\nUses the Toft modification of the classical Shepp-Logan phantom, consisting of 10 ellipses with varying intensities representing different tissue types in a head cross-section.\n\n3D Phantom\n\nGenerates a 3D extension using ellipsoids with:\n\nField-of-view (FOV): 24 cm √ó 24 cm √ó 20 cm\nModified intensities (√ó10) for inner structures to improve visibility\nToft's intensity modifications for the head (1.0) and skull/brain (-0.8) regions\n\nReferences\n\nShepp, L. A., & Logan, B. F. (1974). \"The Fourier reconstruction of a head section.\" IEEE Transactions on Nuclear Science, 21(3), 21-43.\nToft, P. (1996). \"The Radon Transform - Theory and Implementation.\" PhD thesis, Technical University of Denmark.\n\nSee Also\n\nsimulate_acquisition: Generate k-space data from a phantom\ncoil_sensitivities: Generate sensitivity maps for multi-coil simulation\nAcquisitionInfo: Container for acquisition parameters\n\n\n\n\n\n","category":"function"},{"location":"high-level/simulation/#MriReconstructionToolbox.coil_sensitivities","page":"Simulation Tools","title":"MriReconstructionToolbox.coil_sensitivities","text":"coil_sensitivities(nx::Int, ny::Int, nc::Int) -> Array{ComplexF32, 3}\ncoil_sensitivities(nx::Int, ny::Int, nz::Int, nc::Int) -> Array{ComplexF32, 4}\n\nGenerate simulated sensitivity maps for multi-coil MRI receivers.\n\nPhysics Background\n\nIn parallel MRI, multiple receiver coils are arranged around the imaging subject, each with spatially varying sensitivity profiles. This function simulates realistic coil sensitivity maps based on the physical principles of electromagnetic reception.\n\nPhysical Model\n\nThe sensitivity maps are constructed using:\n\nSpatial Arrangement: Coils are positioned in a circular array around the field of view, with centers at angles 2œÄ(i-1)/nc for coil i, mimicking typical clinical coil arrays.\nMagnitude Profile: Each coil's sensitivity decreases with distance from its center following a Gaussian profile exp(-r¬≤/(2œÉ¬≤)), where r is the distance from the coil center. This reflects the physical reality that receiver coils are most sensitive to signal sources near them, with sensitivity falling off smoothly with distance.\nPhase Variation: A linear phase ramp exp(im(0.5x + 0.3y)) is applied to simulate phase variations due to:\nB‚ÇÄ field inhomogeneities\nReceiver electronics phase offsets\nGeometric positioning effects\nNormalization: The maps are normalized using the root-sum-of-squares across all coils, ensuring that ‚àö(Œ£·µ¢|s·µ¢(x,y)|¬≤) ‚âà 1 at each spatial location. This preserves signal intensity while maintaining spatial encoding information.\n\nArguments\n\nnx::Int: Number of pixels in x-direction\nny::Int: Number of pixels in y-direction\nnz::Int: Number of pixels in z-direction (for 3D sensitivities)\nnc::Int: Number of coils\n\nReturns\n\nArray{ComplexF32, 3}: Sensitivity maps of size (nx, ny, nc), where each slice along dimension 3 represents one coil's complex-valued sensitivity profile.\n\n\n\n\n\n","category":"function"},{"location":"high-level/simulation/#MriReconstructionToolbox.UniformRandomSampling","page":"Simulation Tools","title":"MriReconstructionToolbox.UniformRandomSampling","text":"UniformRandomSampling(acceleration::Float64; center_fraction::Float64=0.1)\n\nCreate a uniform random sampling pattern with the specified acceleration factor and center fraction. The acceleration parameter controls the overall undersampling factor, while the center_fraction parameter specifies the fraction of low-frequency k-space positions to be fully sampled.\n\n\n\n\n\n","category":"type"},{"location":"high-level/simulation/#MriReconstructionToolbox.GaussianDistribution","page":"Simulation Tools","title":"MriReconstructionToolbox.GaussianDistribution","text":"GaussianDistribution(std::Float64=1/3)\n\nCreate a Gaussian variable density distribution with the specified standard deviation std. The sampling probability follows a Gaussian profile centered at k-space center:     W(r) = exp(-0.5 * (r / std)^2), where r is the normalized distance from the k-space center.\n\n\n\n\n\n","category":"type"},{"location":"high-level/simulation/#MriReconstructionToolbox.PolynomialDistribution","page":"Simulation Tools","title":"MriReconstructionToolbox.PolynomialDistribution","text":"PolynomialDistribution(p::Float64=4)\n\nCreate a Polynomial variable density distribution with the specified exponent p. The sampling probability is proportional to power of the distance from the k-space center:     W(r) = (1 - r)^p, where r is the normalized distance from the k-space center.\n\n\n\n\n\n","category":"type"},{"location":"high-level/simulation/#MriReconstructionToolbox.VariableDensitySampling","page":"Simulation Tools","title":"MriReconstructionToolbox.VariableDensitySampling","text":"VariableDensitySampling(distribution::VariableDensityDistribution, acceleration::Float64; center_fraction::Float64=0.1)\n\nCreate a variable density random sampling pattern based on the specified distribution, acceleration factor, and center fraction. The distribution parameter can be either GaussianDistribution or PolynomialDistribution. The acceleration parameter controls the overall undersampling factor, while the center_fraction parameter specifies the fraction of low-frequency k-space positions to be fully sampled.\n\n\n\n\n\n","category":"type"},{"location":"high-level/simulation/#MriReconstructionToolbox.PoissonDiskSampling","page":"Simulation Tools","title":"MriReconstructionToolbox.PoissonDiskSampling","text":"PoissonDiskSampling(acceleration::Float64, center_fraction::Float64=0.1)\n\nCreate a Poisson disk sampling pattern with the specified acceleration factor and center fraction. The acceleration parameter controls the overall undersampling factor, while the center_fraction parameter specifies the fraction of low-frequency k-space positions to be fully sampled.\n\n\n\n\n\n","category":"type"},{"location":"high-level/simulation/#MriReconstructionToolbox.simulate_acquisition","page":"Simulation Tools","title":"MriReconstructionToolbox.simulate_acquisition","text":"simulate_acquisition(image, acq_info::AcquisitionInfo)\n\nSimulate MRI k-space acquisition from a given image using the specified acquisition parameters.\n\nArguments\n\nimage: The input image to be transformed into k-space data. Can be a standard array or a NamedDimsArray.\nacq_info::AcquisitionInfo: An AcquisitionInfo object containing acquisition parameters such as sensitivity maps, subsampling pattern, and whether the acquisition is 3D.\n\nReturns\n\nAn updated AcquisitionInfo object with the simulated k-space data stored in the kspace_data field.\n\n\n\n\n\n","category":"function"}]
}
